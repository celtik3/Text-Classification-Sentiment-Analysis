{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA2dkgJk_ihO",
        "outputId": "1ec50712-ebd1-4a2c-a3d0-23e2f4e1897c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WesNtuCIBQ2",
        "outputId": "71e71a02-b9e4-4fa9-c7b3-8a8fc502f951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping gensim as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m279.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m263.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m280.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y gensim\n",
        "!pip install gensim --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lsnmMijm5U6V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQnxCf1BcRI",
        "outputId": "59cecf4f-19b9-42c2-a650-7f9e5a8c607c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIUZYTcyCSoa"
      },
      "source": [
        "#### **Step 1: Loading the dataset and splitting as train and test.** ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55XslUzkyKUK"
      },
      "source": [
        "- I wanted to proceed with one of the benchmark datasets, IMDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36w1JE89Urmo",
        "outputId": "fed0d9a8-f4f0-424c-cf38-3b4905e207a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              review  label\n",
            "0  One of the other reviewers has mentioned that ...      1\n",
            "1  A wonderful little production. <br /><br />The...      1\n",
            "2  I thought this was a wonderful way to spend ti...      1\n",
            "3  Basically there's a family where a little boy ...      0\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...      1\n"
          ]
        }
      ],
      "source": [
        "## https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "\n",
        "imdb_df = pd.read_csv(\"/content/sample_data/IMDB Dataset.csv\")\n",
        "\n",
        "# Labeling sentiments to 0 and 1 for better handling and dropping the sentiment column.\n",
        "imdb_df['label'] = imdb_df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "imdb_df.drop(columns='sentiment', inplace=True)\n",
        "\n",
        "print(imdb_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BSlLD2D2xxD",
        "outputId": "fdd4ac0c-7bab-4c64-80ca-5698266ebcb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1w---fc6hN2",
        "outputId": "974dff71-723b-444e-e15f-4ede9f82b6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "1    25000\n",
            "0    25000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(imdb_df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-xGR-SO7IMA",
        "outputId": "bb3e6b2b-4e53-4586-a2df-4b9d9b309838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "review    0\n",
            "label     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Confirming that the dataset does not have a null value.\n",
        "print(imdb_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yghNEtfb7bgO",
        "outputId": "077fe0e2-437d-4e97-bbd6-66133889df54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size --> 40000\n",
            "Test size  --> 10000\n"
          ]
        }
      ],
      "source": [
        "## Splitting the dataset as train (%80) and test (%20)\n",
        "\n",
        "imdb_df_train, imdb_df_test = train_test_split(imdb_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train size --> {}\\nTest size  --> {}\".format(len(imdb_df_train), len(imdb_df_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL3cJEzrCo1r"
      },
      "source": [
        "#### **Step 2: Text Preprocessing** ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6FHoBkUQ9Ow-"
      },
      "outputs": [],
      "source": [
        "## First of all, lowercasing the reviews.\n",
        "\n",
        "imdb_df_train_lowercase = []\n",
        "for review in imdb_df_train['review']:\n",
        "    imdb_df_train_lowercase.append(review.lower())\n",
        "\n",
        "imdb_df_test_lowercase = []\n",
        "for review in imdb_df_test['review']:\n",
        "    imdb_df_test_lowercase.append(review.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "O-cB2mrp7j_o",
        "outputId": "4f79f184-a583-453c-a092-ecae02636d00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'that\\'s what i kept asking myself during the many fights, screaming matches, swearing and general mayhem that permeate the 84 minutes. the comparisons also stand up when you think of the one-dimensional characters, who have so little depth that it is virtually impossible to care what happens to them. they are just badly written cyphers for the director to hang his multicultural beliefs on, a topic that has been done much better in other dramas both on tv and the cinema.<br /><br />i must confess, i\\'m not really one for spotting bad performances during a film, but it must be said that nichola burley (as the heroine\\'s slutty best friend) and wasim zakir (as the nasty, bullying brother) were absolutely terrible. i don\\'t know what acting school they graduated from, but if i was them i\\'d apply for a full refund post haste. only samina awan in the lead role manages to impress in a cast of so-called british talent that we\\'ll probably never hear from again. at least, that\\'s the hope. next time, hire a different scout.<br /><br />another intriguing thought is the hideously fashionable soundtrack featuring the likes of snow patrol, ian brown and keane. now, i\\'m a bit of a music fan and i\\'m familiar with most of these artists output, but i didn\\'t recognise any of the tracks during this movie (apart from the omnipresent \"run\"). b-sides, anyone? we get many, many musical montages which telegraph how we\\'re suppose to feel. these are accompanied by such startlingly original images as couples kissing by a swollen lake and canoodling in doorways. this is a problem, as none of the songs convey the mood efficiently, and we realise the director lacks the ability to carry the emotional journey to the audience through storytelling and dialogue alone.<br /><br />the ending is presumably meant to be just desserts, as everybody gets their comeuppance and there is at least one big shock in store.. but i remained resolutely unmoved because the script had given me no-one to root for. it\\'s not enough to tackle a hot-button issue, you have to actually give us a plot that hasn\\'t already been done to death and individuals who are more than window dressing. as it stands, this film is a noble failure, with only the promising lead actress and a few mildly diverting punch-ups to save it from the bin. 4/10. must try harder..'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_df_train_lowercase[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rHxTkVl0DjTz"
      },
      "outputs": [],
      "source": [
        "## https://www.geeksforgeeks.org/python-remove-punctuation-from-string/\n",
        "\n",
        "## Removing punctuation\n",
        "\n",
        "imdb_df_train_no_punct = []\n",
        "for review in imdb_df_train_lowercase:\n",
        "    clean = \"\"\n",
        "    for char in review:\n",
        "        if char not in string.punctuation:\n",
        "            clean += char\n",
        "    imdb_df_train_no_punct.append(clean)\n",
        "\n",
        "imdb_df_test_no_punct = []\n",
        "for review in imdb_df_test_lowercase:\n",
        "    clean = \"\"\n",
        "    for char in review:\n",
        "        if char not in string.punctuation:\n",
        "            clean += char\n",
        "    imdb_df_test_no_punct.append(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "miE7K9TyFEwE",
        "outputId": "a876760a-a313-4be9-b0e7-8ae3ecb47752"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thats what i kept asking myself during the many fights screaming matches swearing and general mayhem that permeate the 84 minutes the comparisons also stand up when you think of the onedimensional characters who have so little depth that it is virtually impossible to care what happens to them they are just badly written cyphers for the director to hang his multicultural beliefs on a topic that has been done much better in other dramas both on tv and the cinemabr br i must confess im not really one for spotting bad performances during a film but it must be said that nichola burley as the heroines slutty best friend and wasim zakir as the nasty bullying brother were absolutely terrible i dont know what acting school they graduated from but if i was them id apply for a full refund post haste only samina awan in the lead role manages to impress in a cast of socalled british talent that well probably never hear from again at least thats the hope next time hire a different scoutbr br another intriguing thought is the hideously fashionable soundtrack featuring the likes of snow patrol ian brown and keane now im a bit of a music fan and im familiar with most of these artists output but i didnt recognise any of the tracks during this movie apart from the omnipresent run bsides anyone we get many many musical montages which telegraph how were suppose to feel these are accompanied by such startlingly original images as couples kissing by a swollen lake and canoodling in doorways this is a problem as none of the songs convey the mood efficiently and we realise the director lacks the ability to carry the emotional journey to the audience through storytelling and dialogue alonebr br the ending is presumably meant to be just desserts as everybody gets their comeuppance and there is at least one big shock in store but i remained resolutely unmoved because the script had given me noone to root for its not enough to tackle a hotbutton issue you have to actually give us a plot that hasnt already been done to death and individuals who are more than window dressing as it stands this film is a noble failure with only the promising lead actress and a few mildly diverting punchups to save it from the bin 410 must try harder'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_df_train_no_punct[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aSQbLAC3FEyi"
      },
      "outputs": [],
      "source": [
        "## Tokenizing the text into words/tokens\n",
        "\n",
        "imdb_train_tokenized = []\n",
        "for review in imdb_df_train_no_punct:\n",
        "    tokens = word_tokenize(review)\n",
        "    imdb_train_tokenized.append(tokens)\n",
        "\n",
        "imdb_test_tokenized = []\n",
        "for review in imdb_df_test_no_punct:\n",
        "    tokens = word_tokenize(review)\n",
        "    imdb_test_tokenized.append(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nQ2p1Q5cFE0d",
        "outputId": "f94001db-ff21-42e9-f383-214967ba8692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thats',\n",
              " 'what',\n",
              " 'i',\n",
              " 'kept',\n",
              " 'asking',\n",
              " 'myself',\n",
              " 'during',\n",
              " 'the',\n",
              " 'many',\n",
              " 'fights',\n",
              " 'screaming',\n",
              " 'matches',\n",
              " 'swearing',\n",
              " 'and',\n",
              " 'general',\n",
              " 'mayhem',\n",
              " 'that',\n",
              " 'permeate',\n",
              " 'the',\n",
              " '84',\n",
              " 'minutes',\n",
              " 'the',\n",
              " 'comparisons',\n",
              " 'also',\n",
              " 'stand',\n",
              " 'up',\n",
              " 'when',\n",
              " 'you',\n",
              " 'think',\n",
              " 'of',\n",
              " 'the',\n",
              " 'onedimensional',\n",
              " 'characters',\n",
              " 'who',\n",
              " 'have',\n",
              " 'so',\n",
              " 'little',\n",
              " 'depth',\n",
              " 'that',\n",
              " 'it',\n",
              " 'is',\n",
              " 'virtually',\n",
              " 'impossible',\n",
              " 'to',\n",
              " 'care',\n",
              " 'what',\n",
              " 'happens',\n",
              " 'to',\n",
              " 'them',\n",
              " 'they',\n",
              " 'are',\n",
              " 'just',\n",
              " 'badly',\n",
              " 'written',\n",
              " 'cyphers',\n",
              " 'for',\n",
              " 'the',\n",
              " 'director',\n",
              " 'to',\n",
              " 'hang',\n",
              " 'his',\n",
              " 'multicultural',\n",
              " 'beliefs',\n",
              " 'on',\n",
              " 'a',\n",
              " 'topic',\n",
              " 'that',\n",
              " 'has',\n",
              " 'been',\n",
              " 'done',\n",
              " 'much',\n",
              " 'better',\n",
              " 'in',\n",
              " 'other',\n",
              " 'dramas',\n",
              " 'both',\n",
              " 'on',\n",
              " 'tv',\n",
              " 'and',\n",
              " 'the',\n",
              " 'cinemabr',\n",
              " 'br',\n",
              " 'i',\n",
              " 'must',\n",
              " 'confess',\n",
              " 'im',\n",
              " 'not',\n",
              " 'really',\n",
              " 'one',\n",
              " 'for',\n",
              " 'spotting',\n",
              " 'bad',\n",
              " 'performances',\n",
              " 'during',\n",
              " 'a',\n",
              " 'film',\n",
              " 'but',\n",
              " 'it',\n",
              " 'must',\n",
              " 'be',\n",
              " 'said',\n",
              " 'that',\n",
              " 'nichola',\n",
              " 'burley',\n",
              " 'as',\n",
              " 'the',\n",
              " 'heroines',\n",
              " 'slutty',\n",
              " 'best',\n",
              " 'friend',\n",
              " 'and',\n",
              " 'wasim',\n",
              " 'zakir',\n",
              " 'as',\n",
              " 'the',\n",
              " 'nasty',\n",
              " 'bullying',\n",
              " 'brother',\n",
              " 'were',\n",
              " 'absolutely',\n",
              " 'terrible',\n",
              " 'i',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'what',\n",
              " 'acting',\n",
              " 'school',\n",
              " 'they',\n",
              " 'graduated',\n",
              " 'from',\n",
              " 'but',\n",
              " 'if',\n",
              " 'i',\n",
              " 'was',\n",
              " 'them',\n",
              " 'id',\n",
              " 'apply',\n",
              " 'for',\n",
              " 'a',\n",
              " 'full',\n",
              " 'refund',\n",
              " 'post',\n",
              " 'haste',\n",
              " 'only',\n",
              " 'samina',\n",
              " 'awan',\n",
              " 'in',\n",
              " 'the',\n",
              " 'lead',\n",
              " 'role',\n",
              " 'manages',\n",
              " 'to',\n",
              " 'impress',\n",
              " 'in',\n",
              " 'a',\n",
              " 'cast',\n",
              " 'of',\n",
              " 'socalled',\n",
              " 'british',\n",
              " 'talent',\n",
              " 'that',\n",
              " 'well',\n",
              " 'probably',\n",
              " 'never',\n",
              " 'hear',\n",
              " 'from',\n",
              " 'again',\n",
              " 'at',\n",
              " 'least',\n",
              " 'thats',\n",
              " 'the',\n",
              " 'hope',\n",
              " 'next',\n",
              " 'time',\n",
              " 'hire',\n",
              " 'a',\n",
              " 'different',\n",
              " 'scoutbr',\n",
              " 'br',\n",
              " 'another',\n",
              " 'intriguing',\n",
              " 'thought',\n",
              " 'is',\n",
              " 'the',\n",
              " 'hideously',\n",
              " 'fashionable',\n",
              " 'soundtrack',\n",
              " 'featuring',\n",
              " 'the',\n",
              " 'likes',\n",
              " 'of',\n",
              " 'snow',\n",
              " 'patrol',\n",
              " 'ian',\n",
              " 'brown',\n",
              " 'and',\n",
              " 'keane',\n",
              " 'now',\n",
              " 'im',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'of',\n",
              " 'a',\n",
              " 'music',\n",
              " 'fan',\n",
              " 'and',\n",
              " 'im',\n",
              " 'familiar',\n",
              " 'with',\n",
              " 'most',\n",
              " 'of',\n",
              " 'these',\n",
              " 'artists',\n",
              " 'output',\n",
              " 'but',\n",
              " 'i',\n",
              " 'didnt',\n",
              " 'recognise',\n",
              " 'any',\n",
              " 'of',\n",
              " 'the',\n",
              " 'tracks',\n",
              " 'during',\n",
              " 'this',\n",
              " 'movie',\n",
              " 'apart',\n",
              " 'from',\n",
              " 'the',\n",
              " 'omnipresent',\n",
              " 'run',\n",
              " 'bsides',\n",
              " 'anyone',\n",
              " 'we',\n",
              " 'get',\n",
              " 'many',\n",
              " 'many',\n",
              " 'musical',\n",
              " 'montages',\n",
              " 'which',\n",
              " 'telegraph',\n",
              " 'how',\n",
              " 'were',\n",
              " 'suppose',\n",
              " 'to',\n",
              " 'feel',\n",
              " 'these',\n",
              " 'are',\n",
              " 'accompanied',\n",
              " 'by',\n",
              " 'such',\n",
              " 'startlingly',\n",
              " 'original',\n",
              " 'images',\n",
              " 'as',\n",
              " 'couples',\n",
              " 'kissing',\n",
              " 'by',\n",
              " 'a',\n",
              " 'swollen',\n",
              " 'lake',\n",
              " 'and',\n",
              " 'canoodling',\n",
              " 'in',\n",
              " 'doorways',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'problem',\n",
              " 'as',\n",
              " 'none',\n",
              " 'of',\n",
              " 'the',\n",
              " 'songs',\n",
              " 'convey',\n",
              " 'the',\n",
              " 'mood',\n",
              " 'efficiently',\n",
              " 'and',\n",
              " 'we',\n",
              " 'realise',\n",
              " 'the',\n",
              " 'director',\n",
              " 'lacks',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'carry',\n",
              " 'the',\n",
              " 'emotional',\n",
              " 'journey',\n",
              " 'to',\n",
              " 'the',\n",
              " 'audience',\n",
              " 'through',\n",
              " 'storytelling',\n",
              " 'and',\n",
              " 'dialogue',\n",
              " 'alonebr',\n",
              " 'br',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'is',\n",
              " 'presumably',\n",
              " 'meant',\n",
              " 'to',\n",
              " 'be',\n",
              " 'just',\n",
              " 'desserts',\n",
              " 'as',\n",
              " 'everybody',\n",
              " 'gets',\n",
              " 'their',\n",
              " 'comeuppance',\n",
              " 'and',\n",
              " 'there',\n",
              " 'is',\n",
              " 'at',\n",
              " 'least',\n",
              " 'one',\n",
              " 'big',\n",
              " 'shock',\n",
              " 'in',\n",
              " 'store',\n",
              " 'but',\n",
              " 'i',\n",
              " 'remained',\n",
              " 'resolutely',\n",
              " 'unmoved',\n",
              " 'because',\n",
              " 'the',\n",
              " 'script',\n",
              " 'had',\n",
              " 'given',\n",
              " 'me',\n",
              " 'noone',\n",
              " 'to',\n",
              " 'root',\n",
              " 'for',\n",
              " 'its',\n",
              " 'not',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'tackle',\n",
              " 'a',\n",
              " 'hotbutton',\n",
              " 'issue',\n",
              " 'you',\n",
              " 'have',\n",
              " 'to',\n",
              " 'actually',\n",
              " 'give',\n",
              " 'us',\n",
              " 'a',\n",
              " 'plot',\n",
              " 'that',\n",
              " 'hasnt',\n",
              " 'already',\n",
              " 'been',\n",
              " 'done',\n",
              " 'to',\n",
              " 'death',\n",
              " 'and',\n",
              " 'individuals',\n",
              " 'who',\n",
              " 'are',\n",
              " 'more',\n",
              " 'than',\n",
              " 'window',\n",
              " 'dressing',\n",
              " 'as',\n",
              " 'it',\n",
              " 'stands',\n",
              " 'this',\n",
              " 'film',\n",
              " 'is',\n",
              " 'a',\n",
              " 'noble',\n",
              " 'failure',\n",
              " 'with',\n",
              " 'only',\n",
              " 'the',\n",
              " 'promising',\n",
              " 'lead',\n",
              " 'actress',\n",
              " 'and',\n",
              " 'a',\n",
              " 'few',\n",
              " 'mildly',\n",
              " 'diverting',\n",
              " 'punchups',\n",
              " 'to',\n",
              " 'save',\n",
              " 'it',\n",
              " 'from',\n",
              " 'the',\n",
              " 'bin',\n",
              " '410',\n",
              " 'must',\n",
              " 'try',\n",
              " 'harder']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_train_tokenized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dDgpgTXL1d7",
        "outputId": "2ea22ae0-5173-4ab6-b028-d737f3a5db53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(imdb_train_tokenized[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o6J_x_yRFE4v"
      },
      "outputs": [],
      "source": [
        "## https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
        "\n",
        "## Removing stop words\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "imdb_train_filtered = []\n",
        "for tokens in imdb_train_tokenized:\n",
        "    filtered_words = []\n",
        "    for word in tokens:\n",
        "        if word not in stop_words:\n",
        "            filtered_words.append(word)\n",
        "    imdb_train_filtered.append(filtered_words)\n",
        "\n",
        "imdb_test_filtered = []\n",
        "for tokens in imdb_test_tokenized:\n",
        "    filtered_words = []\n",
        "    for word in tokens:\n",
        "        if word not in stop_words:\n",
        "            filtered_words.append(word)\n",
        "    imdb_test_filtered.append(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gAaTm46LKOYm",
        "outputId": "b103adb8-c08f-4ed5-c435-35470d6ef9c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thats',\n",
              " 'kept',\n",
              " 'asking',\n",
              " 'many',\n",
              " 'fights',\n",
              " 'screaming',\n",
              " 'matches',\n",
              " 'swearing',\n",
              " 'general',\n",
              " 'mayhem',\n",
              " 'permeate',\n",
              " '84',\n",
              " 'minutes',\n",
              " 'comparisons',\n",
              " 'also',\n",
              " 'stand',\n",
              " 'think',\n",
              " 'onedimensional',\n",
              " 'characters',\n",
              " 'little',\n",
              " 'depth',\n",
              " 'virtually',\n",
              " 'impossible',\n",
              " 'care',\n",
              " 'happens',\n",
              " 'badly',\n",
              " 'written',\n",
              " 'cyphers',\n",
              " 'director',\n",
              " 'hang',\n",
              " 'multicultural',\n",
              " 'beliefs',\n",
              " 'topic',\n",
              " 'done',\n",
              " 'much',\n",
              " 'better',\n",
              " 'dramas',\n",
              " 'tv',\n",
              " 'cinemabr',\n",
              " 'br',\n",
              " 'must',\n",
              " 'confess',\n",
              " 'im',\n",
              " 'really',\n",
              " 'one',\n",
              " 'spotting',\n",
              " 'bad',\n",
              " 'performances',\n",
              " 'film',\n",
              " 'must',\n",
              " 'said',\n",
              " 'nichola',\n",
              " 'burley',\n",
              " 'heroines',\n",
              " 'slutty',\n",
              " 'best',\n",
              " 'friend',\n",
              " 'wasim',\n",
              " 'zakir',\n",
              " 'nasty',\n",
              " 'bullying',\n",
              " 'brother',\n",
              " 'absolutely',\n",
              " 'terrible',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'acting',\n",
              " 'school',\n",
              " 'graduated',\n",
              " 'id',\n",
              " 'apply',\n",
              " 'full',\n",
              " 'refund',\n",
              " 'post',\n",
              " 'haste',\n",
              " 'samina',\n",
              " 'awan',\n",
              " 'lead',\n",
              " 'role',\n",
              " 'manages',\n",
              " 'impress',\n",
              " 'cast',\n",
              " 'socalled',\n",
              " 'british',\n",
              " 'talent',\n",
              " 'well',\n",
              " 'probably',\n",
              " 'never',\n",
              " 'hear',\n",
              " 'least',\n",
              " 'thats',\n",
              " 'hope',\n",
              " 'next',\n",
              " 'time',\n",
              " 'hire',\n",
              " 'different',\n",
              " 'scoutbr',\n",
              " 'br',\n",
              " 'another',\n",
              " 'intriguing',\n",
              " 'thought',\n",
              " 'hideously',\n",
              " 'fashionable',\n",
              " 'soundtrack',\n",
              " 'featuring',\n",
              " 'likes',\n",
              " 'snow',\n",
              " 'patrol',\n",
              " 'ian',\n",
              " 'brown',\n",
              " 'keane',\n",
              " 'im',\n",
              " 'bit',\n",
              " 'music',\n",
              " 'fan',\n",
              " 'im',\n",
              " 'familiar',\n",
              " 'artists',\n",
              " 'output',\n",
              " 'didnt',\n",
              " 'recognise',\n",
              " 'tracks',\n",
              " 'movie',\n",
              " 'apart',\n",
              " 'omnipresent',\n",
              " 'run',\n",
              " 'bsides',\n",
              " 'anyone',\n",
              " 'get',\n",
              " 'many',\n",
              " 'many',\n",
              " 'musical',\n",
              " 'montages',\n",
              " 'telegraph',\n",
              " 'suppose',\n",
              " 'feel',\n",
              " 'accompanied',\n",
              " 'startlingly',\n",
              " 'original',\n",
              " 'images',\n",
              " 'couples',\n",
              " 'kissing',\n",
              " 'swollen',\n",
              " 'lake',\n",
              " 'canoodling',\n",
              " 'doorways',\n",
              " 'problem',\n",
              " 'none',\n",
              " 'songs',\n",
              " 'convey',\n",
              " 'mood',\n",
              " 'efficiently',\n",
              " 'realise',\n",
              " 'director',\n",
              " 'lacks',\n",
              " 'ability',\n",
              " 'carry',\n",
              " 'emotional',\n",
              " 'journey',\n",
              " 'audience',\n",
              " 'storytelling',\n",
              " 'dialogue',\n",
              " 'alonebr',\n",
              " 'br',\n",
              " 'ending',\n",
              " 'presumably',\n",
              " 'meant',\n",
              " 'desserts',\n",
              " 'everybody',\n",
              " 'gets',\n",
              " 'comeuppance',\n",
              " 'least',\n",
              " 'one',\n",
              " 'big',\n",
              " 'shock',\n",
              " 'store',\n",
              " 'remained',\n",
              " 'resolutely',\n",
              " 'unmoved',\n",
              " 'script',\n",
              " 'given',\n",
              " 'noone',\n",
              " 'root',\n",
              " 'enough',\n",
              " 'tackle',\n",
              " 'hotbutton',\n",
              " 'issue',\n",
              " 'actually',\n",
              " 'give',\n",
              " 'us',\n",
              " 'plot',\n",
              " 'hasnt',\n",
              " 'already',\n",
              " 'done',\n",
              " 'death',\n",
              " 'individuals',\n",
              " 'window',\n",
              " 'dressing',\n",
              " 'stands',\n",
              " 'film',\n",
              " 'noble',\n",
              " 'failure',\n",
              " 'promising',\n",
              " 'lead',\n",
              " 'actress',\n",
              " 'mildly',\n",
              " 'diverting',\n",
              " 'punchups',\n",
              " 'save',\n",
              " 'bin',\n",
              " '410',\n",
              " 'must',\n",
              " 'try',\n",
              " 'harder']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_train_filtered[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-1pmFEhKOa3",
        "outputId": "fa17cd1e-8cb7-4e7d-9f68-d4a31c57fe26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(imdb_train_filtered[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKDffsA4Y76U"
      },
      "source": [
        "- The following code snippet is about cleaning the tokens from the non-alphabetical tokens because when I was handling word_to_idx, I noticed that I was getting weird tokens for the vocabulary, so I wanted to solve that by removing these tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GuqL5gZIaAJ5"
      },
      "outputs": [],
      "source": [
        "imdb_train_alphabetical = []\n",
        "for tokens in imdb_train_filtered:\n",
        "    alphabetical_words = []\n",
        "    for word in tokens:\n",
        "        if word.isalpha():\n",
        "            alphabetical_words.append(word)\n",
        "    imdb_train_alphabetical.append(alphabetical_words)\n",
        "\n",
        "imdb_test_alphabetical = []\n",
        "for tokens in imdb_test_filtered:\n",
        "    alphabetical_words = []\n",
        "    for word in tokens:\n",
        "        if word.isalpha():\n",
        "            alphabetical_words.append(word)\n",
        "    imdb_test_alphabetical.append(alphabetical_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98bYnIPFPMkM"
      },
      "source": [
        "- While handling the lemmatization, I was not receiving proper lemmas because I was not doing POS tagging. Then, I researched online and found how to solve it with NLTK library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yI2mPpiuPph0"
      },
      "outputs": [],
      "source": [
        "## https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
        "\n",
        "## I was receiving Key Error when I followed the link above for the last line, return ''\n",
        "## Since WordNetLemmatizer only supports 4 POS tags, if there is no match, I returned Noun.\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_QDPMCohKOdN"
      },
      "outputs": [],
      "source": [
        "## https://www.nltk.org/api/nltk.stem.WordNetLemmatizer.html?highlight=wordnet\n",
        "## https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
        "\n",
        "## Lemmatizing the tokens\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "imdb_train_lemmatized = []\n",
        "for tokens in imdb_train_alphabetical:\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    lemma_list = []\n",
        "    for word, tag in tagged_tokens:\n",
        "        wordnet_tag = get_wordnet_pos(tag)\n",
        "        lemma = lemmatizer.lemmatize(word, pos=wordnet_tag)\n",
        "        lemma_list.append(lemma)\n",
        "    imdb_train_lemmatized.append(lemma_list)\n",
        "\n",
        "imdb_test_lemmatized = []\n",
        "for tokens in imdb_test_alphabetical:\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    lemma_list = []\n",
        "    for word, tag in tagged_tokens:\n",
        "        wordnet_tag = get_wordnet_pos(tag)\n",
        "        lemma = lemmatizer.lemmatize(word, pos=wordnet_tag)\n",
        "        lemma_list.append(lemma)\n",
        "    imdb_test_lemmatized.append(lemma_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KMmXZfcWKOfQ",
        "outputId": "535c59f2-b40d-4f2c-a615-831c83d54215"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thats',\n",
              " 'keep',\n",
              " 'ask',\n",
              " 'many',\n",
              " 'fight',\n",
              " 'scream',\n",
              " 'match',\n",
              " 'swear',\n",
              " 'general',\n",
              " 'mayhem',\n",
              " 'permeate',\n",
              " 'minute',\n",
              " 'comparison',\n",
              " 'also',\n",
              " 'stand',\n",
              " 'think',\n",
              " 'onedimensional',\n",
              " 'character',\n",
              " 'little',\n",
              " 'depth',\n",
              " 'virtually',\n",
              " 'impossible',\n",
              " 'care',\n",
              " 'happen',\n",
              " 'badly',\n",
              " 'write',\n",
              " 'cypher',\n",
              " 'director',\n",
              " 'hang',\n",
              " 'multicultural',\n",
              " 'belief',\n",
              " 'topic',\n",
              " 'do',\n",
              " 'much',\n",
              " 'well',\n",
              " 'dramas',\n",
              " 'tv',\n",
              " 'cinemabr',\n",
              " 'br',\n",
              " 'must',\n",
              " 'confess',\n",
              " 'im',\n",
              " 'really',\n",
              " 'one',\n",
              " 'spot',\n",
              " 'bad',\n",
              " 'performance',\n",
              " 'film',\n",
              " 'must',\n",
              " 'say',\n",
              " 'nichola',\n",
              " 'burley',\n",
              " 'heroine',\n",
              " 'slutty',\n",
              " 'best',\n",
              " 'friend',\n",
              " 'wasim',\n",
              " 'zakir',\n",
              " 'nasty',\n",
              " 'bullying',\n",
              " 'brother',\n",
              " 'absolutely',\n",
              " 'terrible',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'act',\n",
              " 'school',\n",
              " 'graduate',\n",
              " 'id',\n",
              " 'apply',\n",
              " 'full',\n",
              " 'refund',\n",
              " 'post',\n",
              " 'haste',\n",
              " 'samina',\n",
              " 'awan',\n",
              " 'lead',\n",
              " 'role',\n",
              " 'manages',\n",
              " 'impress',\n",
              " 'cast',\n",
              " 'socalled',\n",
              " 'british',\n",
              " 'talent',\n",
              " 'well',\n",
              " 'probably',\n",
              " 'never',\n",
              " 'hear',\n",
              " 'least',\n",
              " 'thats',\n",
              " 'hope',\n",
              " 'next',\n",
              " 'time',\n",
              " 'hire',\n",
              " 'different',\n",
              " 'scoutbr',\n",
              " 'br',\n",
              " 'another',\n",
              " 'intriguing',\n",
              " 'think',\n",
              " 'hideously',\n",
              " 'fashionable',\n",
              " 'soundtrack',\n",
              " 'feature',\n",
              " 'like',\n",
              " 'snow',\n",
              " 'patrol',\n",
              " 'ian',\n",
              " 'brown',\n",
              " 'keane',\n",
              " 'im',\n",
              " 'bit',\n",
              " 'music',\n",
              " 'fan',\n",
              " 'im',\n",
              " 'familiar',\n",
              " 'artist',\n",
              " 'output',\n",
              " 'didnt',\n",
              " 'recognise',\n",
              " 'track',\n",
              " 'movie',\n",
              " 'apart',\n",
              " 'omnipresent',\n",
              " 'run',\n",
              " 'bsides',\n",
              " 'anyone',\n",
              " 'get',\n",
              " 'many',\n",
              " 'many',\n",
              " 'musical',\n",
              " 'montage',\n",
              " 'telegraph',\n",
              " 'suppose',\n",
              " 'feel',\n",
              " 'accompany',\n",
              " 'startlingly',\n",
              " 'original',\n",
              " 'image',\n",
              " 'couple',\n",
              " 'kiss',\n",
              " 'swollen',\n",
              " 'lake',\n",
              " 'canoodling',\n",
              " 'doorway',\n",
              " 'problem',\n",
              " 'none',\n",
              " 'song',\n",
              " 'convey',\n",
              " 'mood',\n",
              " 'efficiently',\n",
              " 'realise',\n",
              " 'director',\n",
              " 'lack',\n",
              " 'ability',\n",
              " 'carry',\n",
              " 'emotional',\n",
              " 'journey',\n",
              " 'audience',\n",
              " 'storytelling',\n",
              " 'dialogue',\n",
              " 'alonebr',\n",
              " 'br',\n",
              " 'end',\n",
              " 'presumably',\n",
              " 'mean',\n",
              " 'dessert',\n",
              " 'everybody',\n",
              " 'get',\n",
              " 'comeuppance',\n",
              " 'least',\n",
              " 'one',\n",
              " 'big',\n",
              " 'shock',\n",
              " 'store',\n",
              " 'remain',\n",
              " 'resolutely',\n",
              " 'unmoved',\n",
              " 'script',\n",
              " 'give',\n",
              " 'noone',\n",
              " 'root',\n",
              " 'enough',\n",
              " 'tackle',\n",
              " 'hotbutton',\n",
              " 'issue',\n",
              " 'actually',\n",
              " 'give',\n",
              " 'u',\n",
              " 'plot',\n",
              " 'hasnt',\n",
              " 'already',\n",
              " 'do',\n",
              " 'death',\n",
              " 'individual',\n",
              " 'window',\n",
              " 'dress',\n",
              " 'stand',\n",
              " 'film',\n",
              " 'noble',\n",
              " 'failure',\n",
              " 'promise',\n",
              " 'lead',\n",
              " 'actress',\n",
              " 'mildly',\n",
              " 'divert',\n",
              " 'punchups',\n",
              " 'save',\n",
              " 'bin',\n",
              " 'must',\n",
              " 'try',\n",
              " 'harder']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_train_lemmatized[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PjdB_eFUPeC"
      },
      "source": [
        "- The above result is not perfect for sure, but I still wanted to lemmatize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Nh4T-Uae-7"
      },
      "source": [
        "- I wanted to go with word2vec because it is the used method for LSTM example in the class. I will try to follow that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS9XskYr-6bz",
        "outputId": "c594e49c-75d6-48d8-941b-25c2774eb9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R1ft7UvgaXWv"
      },
      "outputs": [],
      "source": [
        "## https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.load_word2vec_format\n",
        "## https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
        "## https://radimrehurek.com/gensim/models/word2vec.html\n",
        "## https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
        "## https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/\n",
        "## https://github.com/clairett/pytorch-sentiment-classification/tree/master\n",
        "\n",
        "path = \"/content/drive/My Drive/GoogleNews-vectors-negative300.bin\"\n",
        "\n",
        "## Loading the pretrained model as the sample.\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(path, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz6g9gUyKOhg",
        "outputId": "eeb73aab-ccab-4037-f0c7-456f0b5cd635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Confirming if the model works properly.\n",
        "len(word2vec_model[\"king\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "K0Yso2e6EeVq"
      },
      "outputs": [],
      "source": [
        "## I am trying to follow the sample code's method to understand properly.\n",
        "## So, here, I am creating my own vocabulary from the lemmatized training data.\n",
        "\n",
        "imdb_vocab = set()\n",
        "for tokens in imdb_train_lemmatized:\n",
        "    for word in tokens:\n",
        "        imdb_vocab.add(word)\n",
        "\n",
        "## Sorting the vocabulary and creating the word-to-index dictionary as the sample.\n",
        "## I left the index 0 for the padding for LSTM.\n",
        "imdb_vocab = sorted(list(imdb_vocab))\n",
        "word_to_idx = {}\n",
        "for i in range(len(imdb_vocab)):\n",
        "    word_to_idx[imdb_vocab[i]] = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "opAeqcS1jAwu",
        "outputId": "3f8de6be-a230-4022-e314-e766c65e8815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'aa': 1,\n",
              " 'aaa': 2,\n",
              " 'aaaaaaaaaaaahhhhhhhhhhhhhh': 3,\n",
              " 'aaaaaaaargh': 4,\n",
              " 'aaaaagh': 5,\n",
              " 'aaaaah': 6,\n",
              " 'aaaaargh': 7,\n",
              " 'aaaaatchkah': 8,\n",
              " 'aaaaaw': 9,\n",
              " 'aaaahhhhhh': 10,\n",
              " 'aaaahhhhhhh': 11,\n",
              " 'aaaand': 12,\n",
              " 'aaaarrgh': 13,\n",
              " 'aaaawwwwww': 14,\n",
              " 'aaah': 15,\n",
              " 'aaahhhhhhh': 16,\n",
              " 'aaahthe': 17,\n",
              " 'aaand': 18,\n",
              " 'aaargh': 19,\n",
              " 'aaarrrghim': 20,\n",
              " 'aaaugh': 21,\n",
              " 'aab': 22,\n",
              " 'aachen': 23,\n",
              " 'aada': 24,\n",
              " 'aadha': 25,\n",
              " 'aadmittedly': 26,\n",
              " 'aag': 27,\n",
              " 'aage': 28,\n",
              " 'aaghh': 29,\n",
              " 'aah': 30,\n",
              " 'aahed': 31,\n",
              " 'aahhh': 32,\n",
              " 'aahhhh': 33,\n",
              " 'aaila': 34,\n",
              " 'aailiyah': 35,\n",
              " 'aaja': 36,\n",
              " 'aajala': 37,\n",
              " 'aakash': 38,\n",
              " 'aake': 39,\n",
              " 'aaker': 40,\n",
              " 'aalcc': 41,\n",
              " 'aaliyah': 42,\n",
              " 'aaliyahs': 43,\n",
              " 'aalox': 44,\n",
              " 'aames': 45,\n",
              " 'aamesbr': 46,\n",
              " 'aamess': 47,\n",
              " 'aamilne': 48,\n",
              " 'aamir': 49,\n",
              " 'aamirbr': 50,\n",
              " 'aamirs': 51,\n",
              " 'aamirsalmanraveenakarishma': 52,\n",
              " 'aamr': 53,\n",
              " 'aan': 54,\n",
              " 'aankh': 55,\n",
              " 'aankhen': 56,\n",
              " 'aap': 57,\n",
              " 'aapke': 58,\n",
              " 'aapkey': 59,\n",
              " 'aaran': 60,\n",
              " 'aardman': 61,\n",
              " 'aardmanbr': 62,\n",
              " 'aardmans': 63,\n",
              " 'aardvark': 64,\n",
              " 'aarf': 65,\n",
              " 'aargh': 66,\n",
              " 'aarika': 67,\n",
              " 'aaron': 68,\n",
              " 'aaronbr': 69,\n",
              " 'aaroncurb': 70,\n",
              " 'aaronjd': 71,\n",
              " 'aarp': 72,\n",
              " 'aashok': 73,\n",
              " 'aasize': 74,\n",
              " 'aasmaan': 75,\n",
              " 'aasman': 76,\n",
              " 'aatish': 77,\n",
              " 'aaton': 78,\n",
              " 'aau': 79,\n",
              " 'aauugghh': 80,\n",
              " 'aavjo': 81,\n",
              " 'aawip': 82,\n",
              " 'aaww': 83,\n",
              " 'ab': 84,\n",
              " 'aba': 85,\n",
              " 'aback': 86,\n",
              " 'abagail': 87,\n",
              " 'abanazer': 88,\n",
              " 'abandon': 89,\n",
              " 'abandonbr': 90,\n",
              " 'abandoned': 91,\n",
              " 'abandoning': 92,\n",
              " 'abandoningbr': 93,\n",
              " 'abandonment': 94,\n",
              " 'abanks': 95,\n",
              " 'abash': 96,\n",
              " 'abashidze': 97,\n",
              " 'abate': 98,\n",
              " 'abatement': 99,\n",
              " 'abattoir': 100,\n",
              " 'abba': 101,\n",
              " 'abbad': 102,\n",
              " 'abbas': 103,\n",
              " 'abbasi': 104,\n",
              " 'abbastyle': 105,\n",
              " 'abbe': 106,\n",
              " 'abbey': 107,\n",
              " 'abbeybr': 108,\n",
              " 'abbeys': 109,\n",
              " 'abbie': 110,\n",
              " 'abbot': 111,\n",
              " 'abbotcostello': 112,\n",
              " 'abbott': 113,\n",
              " 'abbottbr': 114,\n",
              " 'abbottcostello': 115,\n",
              " 'abbotts': 116,\n",
              " 'abbottwe': 117,\n",
              " 'abbottwhich': 118,\n",
              " 'abbreviate': 119,\n",
              " 'abbreviated': 120,\n",
              " 'abbu': 121,\n",
              " 'abby': 122,\n",
              " 'abbys': 123,\n",
              " 'abbyss': 124,\n",
              " 'abc': 125,\n",
              " 'abcbr': 126,\n",
              " 'abccom': 127,\n",
              " 'abcd': 128,\n",
              " 'abcrelease': 129,\n",
              " 'abcs': 130,\n",
              " 'abcsears': 131,\n",
              " 'abctv': 132,\n",
              " 'abcwe': 133,\n",
              " 'abd': 134,\n",
              " 'abdalla': 135,\n",
              " 'abderrahmane': 136,\n",
              " 'abdicate': 137,\n",
              " 'abdomen': 138,\n",
              " 'abdominal': 139,\n",
              " 'abdoo': 140,\n",
              " 'abduct': 141,\n",
              " 'abducted': 142,\n",
              " 'abductedbr': 143,\n",
              " 'abductee': 144,\n",
              " 'abduction': 145,\n",
              " 'abductionbr': 146,\n",
              " 'abductiontype': 147,\n",
              " 'abductor': 148,\n",
              " 'abducts': 149,\n",
              " 'abduhamdi': 150,\n",
              " 'abdul': 151,\n",
              " 'abdullah': 152,\n",
              " 'abdulrahman': 153,\n",
              " 'abe': 154,\n",
              " 'abecassis': 155,\n",
              " 'abed': 156,\n",
              " 'abedalla': 157,\n",
              " 'abedded': 158,\n",
              " 'abel': 159,\n",
              " 'abell': 160,\n",
              " 'abercrombie': 161,\n",
              " 'abercrombiefitch': 162,\n",
              " 'aberdeen': 163,\n",
              " 'aberdeenbr': 164,\n",
              " 'abernathie': 165,\n",
              " 'abernathy': 166,\n",
              " 'abernethie': 167,\n",
              " 'aberrant': 168,\n",
              " 'aberration': 169,\n",
              " 'aberystwyth': 170,\n",
              " 'abet': 171,\n",
              " 'abetted': 172,\n",
              " 'abeyance': 173,\n",
              " 'abfab': 174,\n",
              " 'abgail': 175,\n",
              " 'abhay': 176,\n",
              " 'abhays': 177,\n",
              " 'abhi': 178,\n",
              " 'abhijeet': 179,\n",
              " 'abhijeetrehan': 180,\n",
              " 'abhimaan': 181,\n",
              " 'abhisheh': 182,\n",
              " 'abhishek': 183,\n",
              " 'abhisheks': 184,\n",
              " 'abhor': 185,\n",
              " 'abhorent': 186,\n",
              " 'abhorrd': 187,\n",
              " 'abhorrence': 188,\n",
              " 'abhorrent': 189,\n",
              " 'abhors': 190,\n",
              " 'abide': 191,\n",
              " 'abides': 192,\n",
              " 'abigail': 193,\n",
              " 'abigails': 194,\n",
              " 'abigil': 195,\n",
              " 'abilene': 196,\n",
              " 'abilities': 197,\n",
              " 'abilitiesbr': 198,\n",
              " 'abilitiesput': 199,\n",
              " 'abilitiessome': 200,\n",
              " 'ability': 201,\n",
              " 'abilitybr': 202,\n",
              " 'abilityof': 203,\n",
              " 'abilitys': 204,\n",
              " 'abilitytalent': 205,\n",
              " 'abirrrd': 206,\n",
              " 'abishag': 207,\n",
              " 'abishai': 208,\n",
              " 'abishek': 209,\n",
              " 'abisheks': 210,\n",
              " 'abit': 211,\n",
              " 'abject': 212,\n",
              " 'abjectly': 213,\n",
              " 'ablaze': 214,\n",
              " 'ablazeso': 215,\n",
              " 'able': 216,\n",
              " 'ableand': 217,\n",
              " 'ablebodied': 218,\n",
              " 'ablebr': 219,\n",
              " 'abler': 220,\n",
              " 'ably': 221,\n",
              " 'abm': 222,\n",
              " 'abnegate': 223,\n",
              " 'abner': 224,\n",
              " 'abnormal': 225,\n",
              " 'abnormality': 226,\n",
              " 'abnormally': 227,\n",
              " 'abo': 228,\n",
              " 'aboard': 229,\n",
              " 'aboardbr': 230,\n",
              " 'aboardnot': 231,\n",
              " 'abode': 232,\n",
              " 'abodelab': 233,\n",
              " 'abodes': 234,\n",
              " 'abolish': 235,\n",
              " 'abolition': 236,\n",
              " 'abolitionism': 237,\n",
              " 'abolitionist': 238,\n",
              " 'abolitionists': 239,\n",
              " 'abomb': 240,\n",
              " 'abombbr': 241,\n",
              " 'abominable': 242,\n",
              " 'abominablebr': 243,\n",
              " 'abominably': 244,\n",
              " 'abomination': 245,\n",
              " 'abominationbr': 246,\n",
              " 'abominationits': 247,\n",
              " 'abominator': 248,\n",
              " 'abominibal': 249,\n",
              " 'abominável': 250,\n",
              " 'aboooot': 251,\n",
              " 'aboout': 252,\n",
              " 'aborigin': 253,\n",
              " 'aboriginal': 254,\n",
              " 'aboriginals': 255,\n",
              " 'aborigine': 256,\n",
              " 'aboriginebr': 257,\n",
              " 'aboriginee': 258,\n",
              " 'aboriginies': 259,\n",
              " 'aborigins': 260,\n",
              " 'aborigone': 261,\n",
              " 'abort': 262,\n",
              " 'aborted': 263,\n",
              " 'abortion': 264,\n",
              " 'abortionbr': 265,\n",
              " 'abortionist': 266,\n",
              " 'abortionistbr': 267,\n",
              " 'abortive': 268,\n",
              " 'abott': 269,\n",
              " 'abou': 270,\n",
              " 'abound': 271,\n",
              " 'aboundafter': 272,\n",
              " 'aboundand': 273,\n",
              " 'aboundbr': 274,\n",
              " 'aboundcoming': 275,\n",
              " 'abounded': 276,\n",
              " 'abounds': 277,\n",
              " 'aboundsbr': 278,\n",
              " 'aboundseverything': 279,\n",
              " 'aboundsnot': 280,\n",
              " 'aboutafter': 281,\n",
              " 'aboutagirly': 282,\n",
              " 'aboutand': 283,\n",
              " 'aboutarent': 284,\n",
              " 'aboutas': 285,\n",
              " 'aboutbest': 286,\n",
              " 'aboutbr': 287,\n",
              " 'aboutcombining': 288,\n",
              " 'aboutcrudbr': 289,\n",
              " 'aboutface': 290,\n",
              " 'aboutghoulies': 291,\n",
              " 'abouti': 292,\n",
              " 'aboutim': 293,\n",
              " 'aboutit': 294,\n",
              " 'aboutlets': 295,\n",
              " 'aboutno': 296,\n",
              " 'aboutnot': 297,\n",
              " 'aboutor': 298,\n",
              " 'aboutprobably': 299,\n",
              " 'abouts': 300,\n",
              " 'aboutsays': 301,\n",
              " 'aboutsimply': 302,\n",
              " 'aboutthat': 303,\n",
              " 'aboutthe': 304,\n",
              " 'aboutthen': 305,\n",
              " 'aboutthere': 306,\n",
              " 'aboutthey': 307,\n",
              " 'abouttobecouple': 308,\n",
              " 'aboutyou': 309,\n",
              " 'aboveaverage': 310,\n",
              " 'abovebr': 311,\n",
              " 'aboveground': 312,\n",
              " 'abovementioned': 313,\n",
              " 'abovepar': 314,\n",
              " 'abovethe': 315,\n",
              " 'abovethelaw': 316,\n",
              " 'abr': 317,\n",
              " 'abra': 318,\n",
              " 'abracadabrantesque': 319,\n",
              " 'abraham': 320,\n",
              " 'abrahambr': 321,\n",
              " 'abrahams': 322,\n",
              " 'abrahamwilliam': 323,\n",
              " 'abrahimi': 324,\n",
              " 'abrahms': 325,\n",
              " 'abram': 326,\n",
              " 'abrams': 327,\n",
              " 'abraracourcix': 328,\n",
              " 'abrasive': 329,\n",
              " 'abrasively': 330,\n",
              " 'abrasiveness': 331,\n",
              " 'abrazo': 332,\n",
              " 'abre': 333,\n",
              " 'abreast': 334,\n",
              " 'abrewing': 335,\n",
              " 'abrhám': 336,\n",
              " 'abridge': 337,\n",
              " 'abridged': 338,\n",
              " 'abridgedwell': 339,\n",
              " 'abridgement': 340,\n",
              " 'abril': 341,\n",
              " 'abrils': 342,\n",
              " 'abroad': 343,\n",
              " 'abroadbr': 344,\n",
              " 'abrogate': 345,\n",
              " 'abromowitz': 346,\n",
              " 'abrupt': 347,\n",
              " 'abruptbr': 348,\n",
              " 'abruptly': 349,\n",
              " 'abruptlybr': 350,\n",
              " 'abruptness': 351,\n",
              " 'abs': 352,\n",
              " 'abscbn': 353,\n",
              " 'abscond': 354,\n",
              " 'abseil': 355,\n",
              " 'absence': 356,\n",
              " 'absencebr': 357,\n",
              " 'absense': 358,\n",
              " 'absent': 359,\n",
              " 'absentbr': 360,\n",
              " 'absentbut': 361,\n",
              " 'absentee': 362,\n",
              " 'absentia': 363,\n",
              " 'absentminded': 364,\n",
              " 'absentmindedly': 365,\n",
              " 'absentmindedness': 366,\n",
              " 'absentthe': 367,\n",
              " 'absolom': 368,\n",
              " 'absoloutely': 369,\n",
              " 'absolute': 370,\n",
              " 'absolutelly': 371,\n",
              " 'absolutely': 372,\n",
              " 'absolutelybr': 373,\n",
              " 'absolutelyconfused': 374,\n",
              " 'absolutelyfantastic': 375,\n",
              " 'absolutelyugh': 376,\n",
              " 'absoluter': 377,\n",
              " 'absolutey': 378,\n",
              " 'absolution': 379,\n",
              " 'absolutlely': 380,\n",
              " 'absolutley': 381,\n",
              " 'absolutly': 382,\n",
              " 'absolve': 383,\n",
              " 'absorb': 384,\n",
              " 'absorbe': 385,\n",
              " 'absorbed': 386,\n",
              " 'absorbedlike': 387,\n",
              " 'absorbent': 388,\n",
              " 'absorbing': 389,\n",
              " 'absorbingly': 390,\n",
              " 'absorbs': 391,\n",
              " 'absorption': 392,\n",
              " 'absoulely': 393,\n",
              " 'absoutely': 394,\n",
              " 'abstain': 395,\n",
              " 'abstinence': 396,\n",
              " 'abstract': 397,\n",
              " 'abstracted': 398,\n",
              " 'abstraction': 399,\n",
              " 'abstruse': 400,\n",
              " 'absurd': 401,\n",
              " 'absurda': 402,\n",
              " 'absurdbr': 403,\n",
              " 'absurdbut': 404,\n",
              " 'absurdest': 405,\n",
              " 'absurdism': 406,\n",
              " 'absurdismbr': 407,\n",
              " 'absurdist': 408,\n",
              " 'absurdity': 409,\n",
              " 'absurditybr': 410,\n",
              " 'absurdityit': 411,\n",
              " 'absurdlooking': 412,\n",
              " 'absurdly': 413,\n",
              " 'absurdlydesigned': 414,\n",
              " 'absurdness': 415,\n",
              " 'absurdsurreal': 416,\n",
              " 'absurdthe': 417,\n",
              " 'absurdyetwinning': 418,\n",
              " 'abt': 419,\n",
              " 'abu': 420,\n",
              " 'abudantly': 421,\n",
              " 'abudget': 422,\n",
              " 'abuelita': 423,\n",
              " 'abuelo': 424,\n",
              " 'abuhabwho': 425,\n",
              " 'abundance': 426,\n",
              " 'abundancebr': 427,\n",
              " 'abundant': 428,\n",
              " 'abundantly': 429,\n",
              " 'abundantlywithout': 430,\n",
              " 'abus': 431,\n",
              " 'abuse': 432,\n",
              " 'abuseand': 433,\n",
              " 'abusebr': 434,\n",
              " 'abused': 435,\n",
              " 'abusedabusive': 436,\n",
              " 'abusedid': 437,\n",
              " 'abuser': 438,\n",
              " 'abusetorture': 439,\n",
              " 'abusin': 440,\n",
              " 'abusive': 441,\n",
              " 'abusivebr': 442,\n",
              " 'abusivehe': 443,\n",
              " 'abusively': 444,\n",
              " 'abusympathetic': 445,\n",
              " 'abut': 446,\n",
              " 'abuzz': 447,\n",
              " 'abvious': 448,\n",
              " 'aby': 449,\n",
              " 'abydos': 450,\n",
              " 'abynes': 451,\n",
              " 'abysmal': 452,\n",
              " 'abysmalbesides': 453,\n",
              " 'abysmalbr': 454,\n",
              " 'abysmalit': 455,\n",
              " 'abysmally': 456,\n",
              " 'abysmalthe': 457,\n",
              " 'abyss': 458,\n",
              " 'abyssbr': 459,\n",
              " 'abyssmal': 460,\n",
              " 'abysymal': 461,\n",
              " 'ac': 462,\n",
              " 'acacia': 463,\n",
              " 'acadamy': 464,\n",
              " 'acadamybr': 465,\n",
              " 'academe': 466,\n",
              " 'academia': 467,\n",
              " 'academian': 468,\n",
              " 'academic': 469,\n",
              " 'academically': 470,\n",
              " 'academicbr': 471,\n",
              " 'academy': 472,\n",
              " 'academyaward': 473,\n",
              " 'academyawardwinning': 474,\n",
              " 'academybr': 475,\n",
              " 'academys': 476,\n",
              " 'acadian': 477,\n",
              " 'acadiana': 478,\n",
              " 'acadmey': 479,\n",
              " 'acaka': 480,\n",
              " 'acandy': 481,\n",
              " 'acapella': 482,\n",
              " 'acapulco': 483,\n",
              " 'acc': 484,\n",
              " 'accapella': 485,\n",
              " 'accede': 486,\n",
              " 'accelerant': 487,\n",
              " 'accelerate': 488,\n",
              " 'acceleratebr': 489,\n",
              " 'accelerated': 490,\n",
              " 'accelerates': 491,\n",
              " 'accelerati': 492,\n",
              " 'acceleration': 493,\n",
              " 'accelerator': 494,\n",
              " 'accellerant': 495,\n",
              " 'accent': 496,\n",
              " 'accentand': 497,\n",
              " 'accentbody': 498,\n",
              " 'accentbr': 499,\n",
              " 'accentbut': 500,\n",
              " 'accented': 501,\n",
              " 'accentfree': 502,\n",
              " 'accenthes': 503,\n",
              " 'accentit': 504,\n",
              " 'accentsbr': 505,\n",
              " 'accentseverything': 506,\n",
              " 'accentsget': 507,\n",
              " 'accentsthe': 508,\n",
              " 'accentuate': 509,\n",
              " 'accentuates': 510,\n",
              " 'accentuation': 511,\n",
              " 'acceotable': 512,\n",
              " 'accept': 513,\n",
              " 'acceptable': 514,\n",
              " 'acceptablebr': 515,\n",
              " 'acceptablefinally': 516,\n",
              " 'acceptableit': 517,\n",
              " 'acceptablethe': 518,\n",
              " 'acceptably': 519,\n",
              " 'acceptance': 520,\n",
              " 'acceptancebr': 521,\n",
              " 'acceptation': 522,\n",
              " 'acceptbr': 523,\n",
              " 'accepted': 524,\n",
              " 'acceptedbr': 525,\n",
              " 'acceptedlets': 526,\n",
              " 'acceptence': 527,\n",
              " 'accepting': 528,\n",
              " 'acceptingbr': 529,\n",
              " 'acceptingly': 530,\n",
              " 'acception': 531,\n",
              " 'accepts': 532,\n",
              " 'acceptsbr': 533,\n",
              " 'accesible': 534,\n",
              " 'access': 535,\n",
              " 'accessability': 536,\n",
              " 'accessbr': 537,\n",
              " 'accessibility': 538,\n",
              " 'accessible': 539,\n",
              " 'accessibleso': 540,\n",
              " 'accession': 541,\n",
              " 'accessorizing': 542,\n",
              " 'accessory': 543,\n",
              " 'accidence': 544,\n",
              " 'accident': 545,\n",
              " 'accidentafter': 546,\n",
              " 'accidental': 547,\n",
              " 'accidentally': 548,\n",
              " 'accidentallypurposely': 549,\n",
              " 'accidentand': 550,\n",
              " 'accidentbr': 551,\n",
              " 'accidentdeath': 552,\n",
              " 'accidentee': 553,\n",
              " 'accidenthe': 554,\n",
              " 'accidenthis': 555,\n",
              " 'accidentially': 556,\n",
              " 'accidentin': 557,\n",
              " 'accidentit': 558,\n",
              " 'accidentlazy': 559,\n",
              " 'accidently': 560,\n",
              " 'accidentnot': 561,\n",
              " 'accidentprone': 562,\n",
              " 'accidents': 563,\n",
              " 'accidentsampedro': 564,\n",
              " 'accidentso': 565,\n",
              " 'accidentsuicidehomicide': 566,\n",
              " 'accidentthat': 567,\n",
              " 'accidentthe': 568,\n",
              " 'accidentvery': 569,\n",
              " 'accidentwell': 570,\n",
              " 'acclaied': 571,\n",
              " 'acclaim': 572,\n",
              " 'acclaimbr': 573,\n",
              " 'acclaimed': 574,\n",
              " 'acclamation': 575,\n",
              " 'acclimation': 576,\n",
              " 'acclimatisation': 577,\n",
              " 'accolade': 578,\n",
              " 'accoladed': 579,\n",
              " 'accolades': 580,\n",
              " 'accoladesburt': 581,\n",
              " 'accoladesit': 582,\n",
              " 'accommodate': 583,\n",
              " 'accommodation': 584,\n",
              " 'accomodations': 585,\n",
              " 'accompanied': 586,\n",
              " 'accompanies': 587,\n",
              " 'accompaniment': 588,\n",
              " 'accompanist': 589,\n",
              " 'accompany': 590,\n",
              " 'accompanybr': 591,\n",
              " 'accompanying': 592,\n",
              " 'accomplice': 593,\n",
              " 'accomplicebr': 594,\n",
              " 'accomplish': 595,\n",
              " 'accomplishbr': 596,\n",
              " 'accomplished': 597,\n",
              " 'accomplishedbr': 598,\n",
              " 'accomplishedjulie': 599,\n",
              " 'accomplishes': 600,\n",
              " 'accomplishment': 601,\n",
              " 'accomplishmentbr': 602,\n",
              " 'accomplishmentsbr': 603,\n",
              " 'accomplishthe': 604,\n",
              " 'accord': 605,\n",
              " 'accordance': 606,\n",
              " 'accordbr': 607,\n",
              " 'accorded': 608,\n",
              " 'accordedbr': 609,\n",
              " 'accordian': 610,\n",
              " 'accordingly': 611,\n",
              " 'accordinglybr': 612,\n",
              " 'accordinglyhence': 613,\n",
              " 'accordinglyshe': 614,\n",
              " 'accordion': 615,\n",
              " 'accordionlike': 616,\n",
              " 'accorsi': 617,\n",
              " 'accoss': 618,\n",
              " 'accost': 619,\n",
              " 'account': 620,\n",
              " 'accountability': 621,\n",
              " 'accountable': 622,\n",
              " 'accountancy': 623,\n",
              " 'accountand': 624,\n",
              " 'accountant': 625,\n",
              " 'accountantembezzler': 626,\n",
              " 'accountbr': 627,\n",
              " 'accounted': 628,\n",
              " 'accounting': 629,\n",
              " 'accountingbr': 630,\n",
              " 'accountsbr': 631,\n",
              " 'accountsmaybe': 632,\n",
              " 'accountthe': 633,\n",
              " 'accountwerners': 634,\n",
              " 'accouterment': 635,\n",
              " 'accoutrement': 636,\n",
              " 'accowmplished': 637,\n",
              " 'accredit': 638,\n",
              " 'accross': 639,\n",
              " 'accrue': 640,\n",
              " 'accrutements': 641,\n",
              " 'acculturation': 642,\n",
              " 'accumulate': 643,\n",
              " 'accumulated': 644,\n",
              " 'accumulating': 645,\n",
              " 'accumulation': 646,\n",
              " 'accumulator': 647,\n",
              " 'accuracy': 648,\n",
              " 'accuracybr': 649,\n",
              " 'accuracybutin': 650,\n",
              " 'accuracyespecially': 651,\n",
              " 'accuracyness': 652,\n",
              " 'accuracythis': 653,\n",
              " 'accurate': 654,\n",
              " 'accuratebr': 655,\n",
              " 'accuratehenry': 656,\n",
              " 'accurateif': 657,\n",
              " 'accurateloosen': 658,\n",
              " 'accurately': 659,\n",
              " 'accuratelymaybe': 660,\n",
              " 'accurse': 661,\n",
              " 'accusation': 662,\n",
              " 'accusationbr': 663,\n",
              " 'accusatory': 664,\n",
              " 'accuse': 665,\n",
              " 'accused': 666,\n",
              " 'accuseds': 667,\n",
              " 'accusee': 668,\n",
              " 'accuser': 669,\n",
              " 'accuses': 670,\n",
              " 'accussation': 671,\n",
              " 'accussed': 672,\n",
              " 'accustom': 673,\n",
              " 'accustomed': 674,\n",
              " 'accustomedbr': 675,\n",
              " 'acd': 676,\n",
              " 'acdc': 677,\n",
              " 'acdcs': 678,\n",
              " 'acds': 679,\n",
              " 'ace': 680,\n",
              " 'acebr': 681,\n",
              " 'acedemy': 682,\n",
              " 'acerbic': 683,\n",
              " 'acerbity': 684,\n",
              " 'acesiron': 685,\n",
              " 'acetylene': 686,\n",
              " 'aceves': 687,\n",
              " 'ach': 688,\n",
              " 'achaar': 689,\n",
              " 'achangin': 690,\n",
              " 'acharya': 691,\n",
              " 'acharyas': 692,\n",
              " 'achcha': 693,\n",
              " 'ache': 694,\n",
              " 'acheaology': 695,\n",
              " 'acheived': 696,\n",
              " 'achenbach': 697,\n",
              " 'acherhuis': 698,\n",
              " 'achero': 699,\n",
              " 'achievable': 700,\n",
              " 'achieve': 701,\n",
              " 'achievebr': 702,\n",
              " 'achieved': 703,\n",
              " 'achievedbr': 704,\n",
              " 'achievement': 705,\n",
              " 'achievementa': 706,\n",
              " 'achievementand': 707,\n",
              " 'achievementbr': 708,\n",
              " 'achievementhave': 709,\n",
              " 'achievements': 710,\n",
              " 'achievementsbr': 711,\n",
              " 'achiever': 712,\n",
              " 'achievermuch': 713,\n",
              " 'achieves': 714,\n",
              " 'achievingbr': 715,\n",
              " 'achile': 716,\n",
              " 'achille': 717,\n",
              " 'achilleas': 718,\n",
              " 'achilleass': 719,\n",
              " 'achilles': 720,\n",
              " 'achillesbr': 721,\n",
              " 'achillies': 722,\n",
              " 'aching': 723,\n",
              " 'achingly': 724,\n",
              " 'achinglybeautiful': 725,\n",
              " 'achive': 726,\n",
              " 'acholoic': 727,\n",
              " 'achord': 728,\n",
              " 'achra': 729,\n",
              " 'achronological': 730,\n",
              " 'achtung': 731,\n",
              " 'achyra': 732,\n",
              " 'acid': 733,\n",
              " 'acidbr': 734,\n",
              " 'acidently': 735,\n",
              " 'acidic': 736,\n",
              " 'acidify': 737,\n",
              " 'acidintheface': 738,\n",
              " 'acidity': 739,\n",
              " 'acidland': 740,\n",
              " 'acidmushrooms': 741,\n",
              " 'acidtinged': 742,\n",
              " 'acidtongued': 743,\n",
              " 'acidtongues': 744,\n",
              " 'acidtrip': 745,\n",
              " 'acin': 746,\n",
              " 'aciton': 747,\n",
              " 'ack': 748,\n",
              " 'acker': 749,\n",
              " 'ackerman': 750,\n",
              " 'ackland': 751,\n",
              " 'acklandbloom': 752,\n",
              " 'acklands': 753,\n",
              " 'acknowledge': 754,\n",
              " 'acknowledgebr': 755,\n",
              " 'acknowledged': 756,\n",
              " 'acknowledgedbr': 757,\n",
              " 'acknowledgement': 758,\n",
              " 'acknowledgementbut': 759,\n",
              " 'acknowledges': 760,\n",
              " 'acknowledgment': 761,\n",
              " 'ackos': 762,\n",
              " 'ackroyd': 763,\n",
              " 'ackroyds': 764,\n",
              " 'ackward': 765,\n",
              " 'acl': 766,\n",
              " 'aclass': 767,\n",
              " 'aclear': 768,\n",
              " 'aclu': 769,\n",
              " 'acme': 770,\n",
              " 'acmetropolis': 771,\n",
              " 'acmi': 772,\n",
              " 'acne': 773,\n",
              " 'acneaddled': 774,\n",
              " 'acog': 775,\n",
              " 'acolyte': 776,\n",
              " 'acolytes': 777,\n",
              " 'acolytesbr': 778,\n",
              " 'acomplication': 779,\n",
              " 'acording': 780,\n",
              " 'acorn': 781,\n",
              " 'acorns': 782,\n",
              " 'acosta': 783,\n",
              " 'acourtinbr': 784,\n",
              " 'acoustic': 785,\n",
              " 'acp': 786,\n",
              " 'acquaint': 787,\n",
              " 'acquaintaces': 788,\n",
              " 'acquaintance': 789,\n",
              " 'acquaintances': 790,\n",
              " 'acquaintancesbr': 791,\n",
              " 'acquaintancetore': 792,\n",
              " 'acquainted': 793,\n",
              " 'acquart': 794,\n",
              " 'acquartwho': 795,\n",
              " 'acquiesce': 796,\n",
              " 'acquiescence': 797,\n",
              " 'acquire': 798,\n",
              " 'acquired': 799,\n",
              " 'acquires': 800,\n",
              " 'acquisition': 801,\n",
              " 'acquisitive': 802,\n",
              " 'acquit': 803,\n",
              " 'acquitane': 804,\n",
              " 'acquits': 805,\n",
              " 'acquittal': 806,\n",
              " 'acquittalbr': 807,\n",
              " 'acquittance': 808,\n",
              " 'acquitted': 809,\n",
              " 'acrap': 810,\n",
              " 'acre': 811,\n",
              " 'acreage': 812,\n",
              " 'acres': 813,\n",
              " 'acrid': 814,\n",
              " 'acrimonious': 815,\n",
              " 'acrimony': 816,\n",
              " 'acrobat': 817,\n",
              " 'acrobatic': 818,\n",
              " 'acrobatics': 819,\n",
              " 'acrobatty': 820,\n",
              " 'acromegaly': 821,\n",
              " 'acronym': 822,\n",
              " 'acronymic': 823,\n",
              " 'acronyms': 824,\n",
              " 'acropolis': 825,\n",
              " 'across': 826,\n",
              " 'acrossbr': 827,\n",
              " 'acrossgoing': 828,\n",
              " 'acrosstheboard': 829,\n",
              " 'acrossthepond': 830,\n",
              " 'acrown': 831,\n",
              " 'acrylic': 832,\n",
              " 'acs': 833,\n",
              " 'act': 834,\n",
              " 'actally': 835,\n",
              " 'actbr': 836,\n",
              " 'acte': 837,\n",
              " 'acted': 838,\n",
              " 'actedalthough': 839,\n",
              " 'actedand': 840,\n",
              " 'actedblah': 841,\n",
              " 'actedboth': 842,\n",
              " 'actedbr': 843,\n",
              " 'acteddirected': 844,\n",
              " 'actedive': 845,\n",
              " 'actedmanipulated': 846,\n",
              " 'actedparticularly': 847,\n",
              " 'actedsummer': 848,\n",
              " 'actedthe': 849,\n",
              " 'actedyou': 850,\n",
              " 'actelone': 851,\n",
              " 'actess': 852,\n",
              " 'acteurs': 853,\n",
              " 'acthe': 854,\n",
              " 'acti': 855,\n",
              " 'actif': 856,\n",
              " 'actin': 857,\n",
              " 'acting': 858,\n",
              " 'actingabsolutely': 859,\n",
              " 'actingalbert': 860,\n",
              " 'actingalthough': 861,\n",
              " 'actingan': 862,\n",
              " 'actingand': 863,\n",
              " 'actingapart': 864,\n",
              " 'actingat': 865,\n",
              " 'actingbad': 866,\n",
              " 'actingboring': 867,\n",
              " 'actingboss': 868,\n",
              " 'actingbr': 869,\n",
              " 'actingbrilliant': 870,\n",
              " 'actingbut': 871,\n",
              " 'actingcamera': 872,\n",
              " 'actingcharacters': 873,\n",
              " 'actingcheck': 874,\n",
              " 'actingclass': 875,\n",
              " 'actingcomedy': 876,\n",
              " 'actingcrap': 877,\n",
              " 'actingde': 878,\n",
              " 'actingdialog': 879,\n",
              " 'actingdirecting': 880,\n",
              " 'actingdirectingcinematography': 881,\n",
              " 'actingdirectingeffectsmusic': 882,\n",
              " 'actingeffects': 883,\n",
              " 'actingetc': 884,\n",
              " 'actingetcbr': 885,\n",
              " 'actingeven': 886,\n",
              " 'actingexcept': 887,\n",
              " 'actingfair': 888,\n",
              " 'actingforthecamera': 889,\n",
              " 'actinggood': 890,\n",
              " 'actinggreat': 891,\n",
              " 'actinghalf': 892,\n",
              " 'actinghe': 893,\n",
              " 'actinghow': 894,\n",
              " 'actinghoweverwas': 895,\n",
              " 'actingim': 896,\n",
              " 'actingin': 897,\n",
              " 'actingisms': 898,\n",
              " 'actingits': 899,\n",
              " 'actingjob': 900,\n",
              " 'actingla': 901,\n",
              " 'actinglack': 902,\n",
              " 'actinglame': 903,\n",
              " 'actingnicholas': 904,\n",
              " 'actingno': 905,\n",
              " 'actingoften': 906,\n",
              " 'actingon': 907,\n",
              " 'actingor': 908,\n",
              " 'actingout': 909,\n",
              " 'actingperformances': 910,\n",
              " 'actingplot': 911,\n",
              " 'actingplotdirectionwriting': 912,\n",
              " 'actingread': 913,\n",
              " 'actingreally': 914,\n",
              " 'actingricci': 915,\n",
              " 'actingrightdoesnt': 916,\n",
              " 'actingrole': 917,\n",
              " 'actingsactors': 918,\n",
              " 'actingschool': 919,\n",
              " 'actingso': 920,\n",
              " 'actingsomewhat': 921,\n",
              " 'actingsorry': 922,\n",
              " 'actingspecial': 923,\n",
              " 'actingstory': 924,\n",
              " 'actingstreep': 925,\n",
              " 'actingsubtle': 926,\n",
              " 'actingterrible': 927,\n",
              " 'actingthat': 928,\n",
              " 'actingthats': 929,\n",
              " 'actingthe': 930,\n",
              " 'actingthere': 931,\n",
              " 'actingthose': 932,\n",
              " 'actingwell': 933,\n",
              " 'actingwellhmmm': 934,\n",
              " 'actingwhich': 935,\n",
              " 'actingwise': 936,\n",
              " 'actingwowit': 937,\n",
              " 'actingwowthe': 938,\n",
              " 'actingwriting': 939,\n",
              " 'actingyou': 940,\n",
              " 'actio': 941,\n",
              " 'action': 942,\n",
              " 'actiona': 943,\n",
              " 'actionacting': 944,\n",
              " 'actionadventure': 945,\n",
              " 'actionadventureromancecomedies': 946,\n",
              " 'actionand': 947,\n",
              " 'actionanimation': 948,\n",
              " 'actionbased': 949,\n",
              " 'actionbiased': 950,\n",
              " 'actionbloodgore': 951,\n",
              " 'actionbr': 952,\n",
              " 'actionbuff': 953,\n",
              " 'actioncombat': 954,\n",
              " 'actioncomedies': 955,\n",
              " 'actioncomedy': 956,\n",
              " 'actioncrime': 957,\n",
              " 'actiondrama': 958,\n",
              " 'actiondramaand': 959,\n",
              " 'actiondramathriller': 960,\n",
              " 'actioneer': 961,\n",
              " 'actioneers': 962,\n",
              " 'actioneffect': 963,\n",
              " 'actionenhancement': 964,\n",
              " 'actionepic': 965,\n",
              " 'actioner': 966,\n",
              " 'actionerbr': 967,\n",
              " 'actioners': 968,\n",
              " 'actionersbr': 969,\n",
              " 'actionerthriller': 970,\n",
              " 'actionespionagebr': 971,\n",
              " 'actionexcitementeven': 972,\n",
              " 'actionexploitation': 973,\n",
              " 'actionextravaganza': 974,\n",
              " 'actionfan': 975,\n",
              " 'actionfantasy': 976,\n",
              " 'actionfeature': 977,\n",
              " 'actionfest': 978,\n",
              " 'actionfight': 979,\n",
              " 'actionfilled': 980,\n",
              " 'actionfirstclass': 981,\n",
              " 'actionflick': 982,\n",
              " 'actionflickraised': 983,\n",
              " 'actiongruesome': 984,\n",
              " 'actionhajjbut': 985,\n",
              " 'actionhalfanimated': 986,\n",
              " 'actionherioc': 987,\n",
              " 'actionhero': 988,\n",
              " 'actionheroine': 989,\n",
              " 'actionhorror': 990,\n",
              " 'actionhorrorfilm': 991,\n",
              " 'actionhorrorromanticcomedygenre': 992,\n",
              " 'actionish': 993,\n",
              " 'actionjunkie': 994,\n",
              " 'actionlacking': 995,\n",
              " 'actionless': 996,\n",
              " 'actionlevel': 997,\n",
              " 'actionlike': 998,\n",
              " 'actionloaded': 999,\n",
              " 'actionlovers': 1000,\n",
              " ...}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c1PTIRtwVxet",
        "outputId": "5bfe941f-ba12-45e5-b7ce-c2f3cc409123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['aa',\n",
              " 'aaa',\n",
              " 'aaaaaaaaaaaahhhhhhhhhhhhhh',\n",
              " 'aaaaaaaargh',\n",
              " 'aaaaagh',\n",
              " 'aaaaah',\n",
              " 'aaaaargh',\n",
              " 'aaaaatchkah',\n",
              " 'aaaaaw',\n",
              " 'aaaahhhhhh',\n",
              " 'aaaahhhhhhh',\n",
              " 'aaaand',\n",
              " 'aaaarrgh',\n",
              " 'aaaawwwwww',\n",
              " 'aaah',\n",
              " 'aaahhhhhhh',\n",
              " 'aaahthe',\n",
              " 'aaand',\n",
              " 'aaargh',\n",
              " 'aaarrrghim',\n",
              " 'aaaugh',\n",
              " 'aab',\n",
              " 'aachen',\n",
              " 'aada',\n",
              " 'aadha',\n",
              " 'aadmittedly',\n",
              " 'aag',\n",
              " 'aage',\n",
              " 'aaghh',\n",
              " 'aah',\n",
              " 'aahed',\n",
              " 'aahhh',\n",
              " 'aahhhh',\n",
              " 'aaila',\n",
              " 'aailiyah',\n",
              " 'aaja',\n",
              " 'aajala',\n",
              " 'aakash',\n",
              " 'aake',\n",
              " 'aaker',\n",
              " 'aalcc',\n",
              " 'aaliyah',\n",
              " 'aaliyahs',\n",
              " 'aalox',\n",
              " 'aames',\n",
              " 'aamesbr',\n",
              " 'aamess',\n",
              " 'aamilne',\n",
              " 'aamir',\n",
              " 'aamirbr',\n",
              " 'aamirs',\n",
              " 'aamirsalmanraveenakarishma',\n",
              " 'aamr',\n",
              " 'aan',\n",
              " 'aankh',\n",
              " 'aankhen',\n",
              " 'aap',\n",
              " 'aapke',\n",
              " 'aapkey',\n",
              " 'aaran',\n",
              " 'aardman',\n",
              " 'aardmanbr',\n",
              " 'aardmans',\n",
              " 'aardvark',\n",
              " 'aarf',\n",
              " 'aargh',\n",
              " 'aarika',\n",
              " 'aaron',\n",
              " 'aaronbr',\n",
              " 'aaroncurb',\n",
              " 'aaronjd',\n",
              " 'aarp',\n",
              " 'aashok',\n",
              " 'aasize',\n",
              " 'aasmaan',\n",
              " 'aasman',\n",
              " 'aatish',\n",
              " 'aaton',\n",
              " 'aau',\n",
              " 'aauugghh',\n",
              " 'aavjo',\n",
              " 'aawip',\n",
              " 'aaww',\n",
              " 'ab',\n",
              " 'aba',\n",
              " 'aback',\n",
              " 'abagail',\n",
              " 'abanazer',\n",
              " 'abandon',\n",
              " 'abandonbr',\n",
              " 'abandoned',\n",
              " 'abandoning',\n",
              " 'abandoningbr',\n",
              " 'abandonment',\n",
              " 'abanks',\n",
              " 'abash',\n",
              " 'abashidze',\n",
              " 'abate',\n",
              " 'abatement',\n",
              " 'abattoir',\n",
              " 'abba',\n",
              " 'abbad',\n",
              " 'abbas',\n",
              " 'abbasi',\n",
              " 'abbastyle',\n",
              " 'abbe',\n",
              " 'abbey',\n",
              " 'abbeybr',\n",
              " 'abbeys',\n",
              " 'abbie',\n",
              " 'abbot',\n",
              " 'abbotcostello',\n",
              " 'abbott',\n",
              " 'abbottbr',\n",
              " 'abbottcostello',\n",
              " 'abbotts',\n",
              " 'abbottwe',\n",
              " 'abbottwhich',\n",
              " 'abbreviate',\n",
              " 'abbreviated',\n",
              " 'abbu',\n",
              " 'abby',\n",
              " 'abbys',\n",
              " 'abbyss',\n",
              " 'abc',\n",
              " 'abcbr',\n",
              " 'abccom',\n",
              " 'abcd',\n",
              " 'abcrelease',\n",
              " 'abcs',\n",
              " 'abcsears',\n",
              " 'abctv',\n",
              " 'abcwe',\n",
              " 'abd',\n",
              " 'abdalla',\n",
              " 'abderrahmane',\n",
              " 'abdicate',\n",
              " 'abdomen',\n",
              " 'abdominal',\n",
              " 'abdoo',\n",
              " 'abduct',\n",
              " 'abducted',\n",
              " 'abductedbr',\n",
              " 'abductee',\n",
              " 'abduction',\n",
              " 'abductionbr',\n",
              " 'abductiontype',\n",
              " 'abductor',\n",
              " 'abducts',\n",
              " 'abduhamdi',\n",
              " 'abdul',\n",
              " 'abdullah',\n",
              " 'abdulrahman',\n",
              " 'abe',\n",
              " 'abecassis',\n",
              " 'abed',\n",
              " 'abedalla',\n",
              " 'abedded',\n",
              " 'abel',\n",
              " 'abell',\n",
              " 'abercrombie',\n",
              " 'abercrombiefitch',\n",
              " 'aberdeen',\n",
              " 'aberdeenbr',\n",
              " 'abernathie',\n",
              " 'abernathy',\n",
              " 'abernethie',\n",
              " 'aberrant',\n",
              " 'aberration',\n",
              " 'aberystwyth',\n",
              " 'abet',\n",
              " 'abetted',\n",
              " 'abeyance',\n",
              " 'abfab',\n",
              " 'abgail',\n",
              " 'abhay',\n",
              " 'abhays',\n",
              " 'abhi',\n",
              " 'abhijeet',\n",
              " 'abhijeetrehan',\n",
              " 'abhimaan',\n",
              " 'abhisheh',\n",
              " 'abhishek',\n",
              " 'abhisheks',\n",
              " 'abhor',\n",
              " 'abhorent',\n",
              " 'abhorrd',\n",
              " 'abhorrence',\n",
              " 'abhorrent',\n",
              " 'abhors',\n",
              " 'abide',\n",
              " 'abides',\n",
              " 'abigail',\n",
              " 'abigails',\n",
              " 'abigil',\n",
              " 'abilene',\n",
              " 'abilities',\n",
              " 'abilitiesbr',\n",
              " 'abilitiesput',\n",
              " 'abilitiessome',\n",
              " 'ability',\n",
              " 'abilitybr',\n",
              " 'abilityof',\n",
              " 'abilitys',\n",
              " 'abilitytalent',\n",
              " 'abirrrd',\n",
              " 'abishag',\n",
              " 'abishai',\n",
              " 'abishek',\n",
              " 'abisheks',\n",
              " 'abit',\n",
              " 'abject',\n",
              " 'abjectly',\n",
              " 'ablaze',\n",
              " 'ablazeso',\n",
              " 'able',\n",
              " 'ableand',\n",
              " 'ablebodied',\n",
              " 'ablebr',\n",
              " 'abler',\n",
              " 'ably',\n",
              " 'abm',\n",
              " 'abnegate',\n",
              " 'abner',\n",
              " 'abnormal',\n",
              " 'abnormality',\n",
              " 'abnormally',\n",
              " 'abo',\n",
              " 'aboard',\n",
              " 'aboardbr',\n",
              " 'aboardnot',\n",
              " 'abode',\n",
              " 'abodelab',\n",
              " 'abodes',\n",
              " 'abolish',\n",
              " 'abolition',\n",
              " 'abolitionism',\n",
              " 'abolitionist',\n",
              " 'abolitionists',\n",
              " 'abomb',\n",
              " 'abombbr',\n",
              " 'abominable',\n",
              " 'abominablebr',\n",
              " 'abominably',\n",
              " 'abomination',\n",
              " 'abominationbr',\n",
              " 'abominationits',\n",
              " 'abominator',\n",
              " 'abominibal',\n",
              " 'abominável',\n",
              " 'aboooot',\n",
              " 'aboout',\n",
              " 'aborigin',\n",
              " 'aboriginal',\n",
              " 'aboriginals',\n",
              " 'aborigine',\n",
              " 'aboriginebr',\n",
              " 'aboriginee',\n",
              " 'aboriginies',\n",
              " 'aborigins',\n",
              " 'aborigone',\n",
              " 'abort',\n",
              " 'aborted',\n",
              " 'abortion',\n",
              " 'abortionbr',\n",
              " 'abortionist',\n",
              " 'abortionistbr',\n",
              " 'abortive',\n",
              " 'abott',\n",
              " 'abou',\n",
              " 'abound',\n",
              " 'aboundafter',\n",
              " 'aboundand',\n",
              " 'aboundbr',\n",
              " 'aboundcoming',\n",
              " 'abounded',\n",
              " 'abounds',\n",
              " 'aboundsbr',\n",
              " 'aboundseverything',\n",
              " 'aboundsnot',\n",
              " 'aboutafter',\n",
              " 'aboutagirly',\n",
              " 'aboutand',\n",
              " 'aboutarent',\n",
              " 'aboutas',\n",
              " 'aboutbest',\n",
              " 'aboutbr',\n",
              " 'aboutcombining',\n",
              " 'aboutcrudbr',\n",
              " 'aboutface',\n",
              " 'aboutghoulies',\n",
              " 'abouti',\n",
              " 'aboutim',\n",
              " 'aboutit',\n",
              " 'aboutlets',\n",
              " 'aboutno',\n",
              " 'aboutnot',\n",
              " 'aboutor',\n",
              " 'aboutprobably',\n",
              " 'abouts',\n",
              " 'aboutsays',\n",
              " 'aboutsimply',\n",
              " 'aboutthat',\n",
              " 'aboutthe',\n",
              " 'aboutthen',\n",
              " 'aboutthere',\n",
              " 'aboutthey',\n",
              " 'abouttobecouple',\n",
              " 'aboutyou',\n",
              " 'aboveaverage',\n",
              " 'abovebr',\n",
              " 'aboveground',\n",
              " 'abovementioned',\n",
              " 'abovepar',\n",
              " 'abovethe',\n",
              " 'abovethelaw',\n",
              " 'abr',\n",
              " 'abra',\n",
              " 'abracadabrantesque',\n",
              " 'abraham',\n",
              " 'abrahambr',\n",
              " 'abrahams',\n",
              " 'abrahamwilliam',\n",
              " 'abrahimi',\n",
              " 'abrahms',\n",
              " 'abram',\n",
              " 'abrams',\n",
              " 'abraracourcix',\n",
              " 'abrasive',\n",
              " 'abrasively',\n",
              " 'abrasiveness',\n",
              " 'abrazo',\n",
              " 'abre',\n",
              " 'abreast',\n",
              " 'abrewing',\n",
              " 'abrhám',\n",
              " 'abridge',\n",
              " 'abridged',\n",
              " 'abridgedwell',\n",
              " 'abridgement',\n",
              " 'abril',\n",
              " 'abrils',\n",
              " 'abroad',\n",
              " 'abroadbr',\n",
              " 'abrogate',\n",
              " 'abromowitz',\n",
              " 'abrupt',\n",
              " 'abruptbr',\n",
              " 'abruptly',\n",
              " 'abruptlybr',\n",
              " 'abruptness',\n",
              " 'abs',\n",
              " 'abscbn',\n",
              " 'abscond',\n",
              " 'abseil',\n",
              " 'absence',\n",
              " 'absencebr',\n",
              " 'absense',\n",
              " 'absent',\n",
              " 'absentbr',\n",
              " 'absentbut',\n",
              " 'absentee',\n",
              " 'absentia',\n",
              " 'absentminded',\n",
              " 'absentmindedly',\n",
              " 'absentmindedness',\n",
              " 'absentthe',\n",
              " 'absolom',\n",
              " 'absoloutely',\n",
              " 'absolute',\n",
              " 'absolutelly',\n",
              " 'absolutely',\n",
              " 'absolutelybr',\n",
              " 'absolutelyconfused',\n",
              " 'absolutelyfantastic',\n",
              " 'absolutelyugh',\n",
              " 'absoluter',\n",
              " 'absolutey',\n",
              " 'absolution',\n",
              " 'absolutlely',\n",
              " 'absolutley',\n",
              " 'absolutly',\n",
              " 'absolve',\n",
              " 'absorb',\n",
              " 'absorbe',\n",
              " 'absorbed',\n",
              " 'absorbedlike',\n",
              " 'absorbent',\n",
              " 'absorbing',\n",
              " 'absorbingly',\n",
              " 'absorbs',\n",
              " 'absorption',\n",
              " 'absoulely',\n",
              " 'absoutely',\n",
              " 'abstain',\n",
              " 'abstinence',\n",
              " 'abstract',\n",
              " 'abstracted',\n",
              " 'abstraction',\n",
              " 'abstruse',\n",
              " 'absurd',\n",
              " 'absurda',\n",
              " 'absurdbr',\n",
              " 'absurdbut',\n",
              " 'absurdest',\n",
              " 'absurdism',\n",
              " 'absurdismbr',\n",
              " 'absurdist',\n",
              " 'absurdity',\n",
              " 'absurditybr',\n",
              " 'absurdityit',\n",
              " 'absurdlooking',\n",
              " 'absurdly',\n",
              " 'absurdlydesigned',\n",
              " 'absurdness',\n",
              " 'absurdsurreal',\n",
              " 'absurdthe',\n",
              " 'absurdyetwinning',\n",
              " 'abt',\n",
              " 'abu',\n",
              " 'abudantly',\n",
              " 'abudget',\n",
              " 'abuelita',\n",
              " 'abuelo',\n",
              " 'abuhabwho',\n",
              " 'abundance',\n",
              " 'abundancebr',\n",
              " 'abundant',\n",
              " 'abundantly',\n",
              " 'abundantlywithout',\n",
              " 'abus',\n",
              " 'abuse',\n",
              " 'abuseand',\n",
              " 'abusebr',\n",
              " 'abused',\n",
              " 'abusedabusive',\n",
              " 'abusedid',\n",
              " 'abuser',\n",
              " 'abusetorture',\n",
              " 'abusin',\n",
              " 'abusive',\n",
              " 'abusivebr',\n",
              " 'abusivehe',\n",
              " 'abusively',\n",
              " 'abusympathetic',\n",
              " 'abut',\n",
              " 'abuzz',\n",
              " 'abvious',\n",
              " 'aby',\n",
              " 'abydos',\n",
              " 'abynes',\n",
              " 'abysmal',\n",
              " 'abysmalbesides',\n",
              " 'abysmalbr',\n",
              " 'abysmalit',\n",
              " 'abysmally',\n",
              " 'abysmalthe',\n",
              " 'abyss',\n",
              " 'abyssbr',\n",
              " 'abyssmal',\n",
              " 'abysymal',\n",
              " 'ac',\n",
              " 'acacia',\n",
              " 'acadamy',\n",
              " 'acadamybr',\n",
              " 'academe',\n",
              " 'academia',\n",
              " 'academian',\n",
              " 'academic',\n",
              " 'academically',\n",
              " 'academicbr',\n",
              " 'academy',\n",
              " 'academyaward',\n",
              " 'academyawardwinning',\n",
              " 'academybr',\n",
              " 'academys',\n",
              " 'acadian',\n",
              " 'acadiana',\n",
              " 'acadmey',\n",
              " 'acaka',\n",
              " 'acandy',\n",
              " 'acapella',\n",
              " 'acapulco',\n",
              " 'acc',\n",
              " 'accapella',\n",
              " 'accede',\n",
              " 'accelerant',\n",
              " 'accelerate',\n",
              " 'acceleratebr',\n",
              " 'accelerated',\n",
              " 'accelerates',\n",
              " 'accelerati',\n",
              " 'acceleration',\n",
              " 'accelerator',\n",
              " 'accellerant',\n",
              " 'accent',\n",
              " 'accentand',\n",
              " 'accentbody',\n",
              " 'accentbr',\n",
              " 'accentbut',\n",
              " 'accented',\n",
              " 'accentfree',\n",
              " 'accenthes',\n",
              " 'accentit',\n",
              " 'accentsbr',\n",
              " 'accentseverything',\n",
              " 'accentsget',\n",
              " 'accentsthe',\n",
              " 'accentuate',\n",
              " 'accentuates',\n",
              " 'accentuation',\n",
              " 'acceotable',\n",
              " 'accept',\n",
              " 'acceptable',\n",
              " 'acceptablebr',\n",
              " 'acceptablefinally',\n",
              " 'acceptableit',\n",
              " 'acceptablethe',\n",
              " 'acceptably',\n",
              " 'acceptance',\n",
              " 'acceptancebr',\n",
              " 'acceptation',\n",
              " 'acceptbr',\n",
              " 'accepted',\n",
              " 'acceptedbr',\n",
              " 'acceptedlets',\n",
              " 'acceptence',\n",
              " 'accepting',\n",
              " 'acceptingbr',\n",
              " 'acceptingly',\n",
              " 'acception',\n",
              " 'accepts',\n",
              " 'acceptsbr',\n",
              " 'accesible',\n",
              " 'access',\n",
              " 'accessability',\n",
              " 'accessbr',\n",
              " 'accessibility',\n",
              " 'accessible',\n",
              " 'accessibleso',\n",
              " 'accession',\n",
              " 'accessorizing',\n",
              " 'accessory',\n",
              " 'accidence',\n",
              " 'accident',\n",
              " 'accidentafter',\n",
              " 'accidental',\n",
              " 'accidentally',\n",
              " 'accidentallypurposely',\n",
              " 'accidentand',\n",
              " 'accidentbr',\n",
              " 'accidentdeath',\n",
              " 'accidentee',\n",
              " 'accidenthe',\n",
              " 'accidenthis',\n",
              " 'accidentially',\n",
              " 'accidentin',\n",
              " 'accidentit',\n",
              " 'accidentlazy',\n",
              " 'accidently',\n",
              " 'accidentnot',\n",
              " 'accidentprone',\n",
              " 'accidents',\n",
              " 'accidentsampedro',\n",
              " 'accidentso',\n",
              " 'accidentsuicidehomicide',\n",
              " 'accidentthat',\n",
              " 'accidentthe',\n",
              " 'accidentvery',\n",
              " 'accidentwell',\n",
              " 'acclaied',\n",
              " 'acclaim',\n",
              " 'acclaimbr',\n",
              " 'acclaimed',\n",
              " 'acclamation',\n",
              " 'acclimation',\n",
              " 'acclimatisation',\n",
              " 'accolade',\n",
              " 'accoladed',\n",
              " 'accolades',\n",
              " 'accoladesburt',\n",
              " 'accoladesit',\n",
              " 'accommodate',\n",
              " 'accommodation',\n",
              " 'accomodations',\n",
              " 'accompanied',\n",
              " 'accompanies',\n",
              " 'accompaniment',\n",
              " 'accompanist',\n",
              " 'accompany',\n",
              " 'accompanybr',\n",
              " 'accompanying',\n",
              " 'accomplice',\n",
              " 'accomplicebr',\n",
              " 'accomplish',\n",
              " 'accomplishbr',\n",
              " 'accomplished',\n",
              " 'accomplishedbr',\n",
              " 'accomplishedjulie',\n",
              " 'accomplishes',\n",
              " 'accomplishment',\n",
              " 'accomplishmentbr',\n",
              " 'accomplishmentsbr',\n",
              " 'accomplishthe',\n",
              " 'accord',\n",
              " 'accordance',\n",
              " 'accordbr',\n",
              " 'accorded',\n",
              " 'accordedbr',\n",
              " 'accordian',\n",
              " 'accordingly',\n",
              " 'accordinglybr',\n",
              " 'accordinglyhence',\n",
              " 'accordinglyshe',\n",
              " 'accordion',\n",
              " 'accordionlike',\n",
              " 'accorsi',\n",
              " 'accoss',\n",
              " 'accost',\n",
              " 'account',\n",
              " 'accountability',\n",
              " 'accountable',\n",
              " 'accountancy',\n",
              " 'accountand',\n",
              " 'accountant',\n",
              " 'accountantembezzler',\n",
              " 'accountbr',\n",
              " 'accounted',\n",
              " 'accounting',\n",
              " 'accountingbr',\n",
              " 'accountsbr',\n",
              " 'accountsmaybe',\n",
              " 'accountthe',\n",
              " 'accountwerners',\n",
              " 'accouterment',\n",
              " 'accoutrement',\n",
              " 'accowmplished',\n",
              " 'accredit',\n",
              " 'accross',\n",
              " 'accrue',\n",
              " 'accrutements',\n",
              " 'acculturation',\n",
              " 'accumulate',\n",
              " 'accumulated',\n",
              " 'accumulating',\n",
              " 'accumulation',\n",
              " 'accumulator',\n",
              " 'accuracy',\n",
              " 'accuracybr',\n",
              " 'accuracybutin',\n",
              " 'accuracyespecially',\n",
              " 'accuracyness',\n",
              " 'accuracythis',\n",
              " 'accurate',\n",
              " 'accuratebr',\n",
              " 'accuratehenry',\n",
              " 'accurateif',\n",
              " 'accurateloosen',\n",
              " 'accurately',\n",
              " 'accuratelymaybe',\n",
              " 'accurse',\n",
              " 'accusation',\n",
              " 'accusationbr',\n",
              " 'accusatory',\n",
              " 'accuse',\n",
              " 'accused',\n",
              " 'accuseds',\n",
              " 'accusee',\n",
              " 'accuser',\n",
              " 'accuses',\n",
              " 'accussation',\n",
              " 'accussed',\n",
              " 'accustom',\n",
              " 'accustomed',\n",
              " 'accustomedbr',\n",
              " 'acd',\n",
              " 'acdc',\n",
              " 'acdcs',\n",
              " 'acds',\n",
              " 'ace',\n",
              " 'acebr',\n",
              " 'acedemy',\n",
              " 'acerbic',\n",
              " 'acerbity',\n",
              " 'acesiron',\n",
              " 'acetylene',\n",
              " 'aceves',\n",
              " 'ach',\n",
              " 'achaar',\n",
              " 'achangin',\n",
              " 'acharya',\n",
              " 'acharyas',\n",
              " 'achcha',\n",
              " 'ache',\n",
              " 'acheaology',\n",
              " 'acheived',\n",
              " 'achenbach',\n",
              " 'acherhuis',\n",
              " 'achero',\n",
              " 'achievable',\n",
              " 'achieve',\n",
              " 'achievebr',\n",
              " 'achieved',\n",
              " 'achievedbr',\n",
              " 'achievement',\n",
              " 'achievementa',\n",
              " 'achievementand',\n",
              " 'achievementbr',\n",
              " 'achievementhave',\n",
              " 'achievements',\n",
              " 'achievementsbr',\n",
              " 'achiever',\n",
              " 'achievermuch',\n",
              " 'achieves',\n",
              " 'achievingbr',\n",
              " 'achile',\n",
              " 'achille',\n",
              " 'achilleas',\n",
              " 'achilleass',\n",
              " 'achilles',\n",
              " 'achillesbr',\n",
              " 'achillies',\n",
              " 'aching',\n",
              " 'achingly',\n",
              " 'achinglybeautiful',\n",
              " 'achive',\n",
              " 'acholoic',\n",
              " 'achord',\n",
              " 'achra',\n",
              " 'achronological',\n",
              " 'achtung',\n",
              " 'achyra',\n",
              " 'acid',\n",
              " 'acidbr',\n",
              " 'acidently',\n",
              " 'acidic',\n",
              " 'acidify',\n",
              " 'acidintheface',\n",
              " 'acidity',\n",
              " 'acidland',\n",
              " 'acidmushrooms',\n",
              " 'acidtinged',\n",
              " 'acidtongued',\n",
              " 'acidtongues',\n",
              " 'acidtrip',\n",
              " 'acin',\n",
              " 'aciton',\n",
              " 'ack',\n",
              " 'acker',\n",
              " 'ackerman',\n",
              " 'ackland',\n",
              " 'acklandbloom',\n",
              " 'acklands',\n",
              " 'acknowledge',\n",
              " 'acknowledgebr',\n",
              " 'acknowledged',\n",
              " 'acknowledgedbr',\n",
              " 'acknowledgement',\n",
              " 'acknowledgementbut',\n",
              " 'acknowledges',\n",
              " 'acknowledgment',\n",
              " 'ackos',\n",
              " 'ackroyd',\n",
              " 'ackroyds',\n",
              " 'ackward',\n",
              " 'acl',\n",
              " 'aclass',\n",
              " 'aclear',\n",
              " 'aclu',\n",
              " 'acme',\n",
              " 'acmetropolis',\n",
              " 'acmi',\n",
              " 'acne',\n",
              " 'acneaddled',\n",
              " 'acog',\n",
              " 'acolyte',\n",
              " 'acolytes',\n",
              " 'acolytesbr',\n",
              " 'acomplication',\n",
              " 'acording',\n",
              " 'acorn',\n",
              " 'acorns',\n",
              " 'acosta',\n",
              " 'acourtinbr',\n",
              " 'acoustic',\n",
              " 'acp',\n",
              " 'acquaint',\n",
              " 'acquaintaces',\n",
              " 'acquaintance',\n",
              " 'acquaintances',\n",
              " 'acquaintancesbr',\n",
              " 'acquaintancetore',\n",
              " 'acquainted',\n",
              " 'acquart',\n",
              " 'acquartwho',\n",
              " 'acquiesce',\n",
              " 'acquiescence',\n",
              " 'acquire',\n",
              " 'acquired',\n",
              " 'acquires',\n",
              " 'acquisition',\n",
              " 'acquisitive',\n",
              " 'acquit',\n",
              " 'acquitane',\n",
              " 'acquits',\n",
              " 'acquittal',\n",
              " 'acquittalbr',\n",
              " 'acquittance',\n",
              " 'acquitted',\n",
              " 'acrap',\n",
              " 'acre',\n",
              " 'acreage',\n",
              " 'acres',\n",
              " 'acrid',\n",
              " 'acrimonious',\n",
              " 'acrimony',\n",
              " 'acrobat',\n",
              " 'acrobatic',\n",
              " 'acrobatics',\n",
              " 'acrobatty',\n",
              " 'acromegaly',\n",
              " 'acronym',\n",
              " 'acronymic',\n",
              " 'acronyms',\n",
              " 'acropolis',\n",
              " 'across',\n",
              " 'acrossbr',\n",
              " 'acrossgoing',\n",
              " 'acrosstheboard',\n",
              " 'acrossthepond',\n",
              " 'acrown',\n",
              " 'acrylic',\n",
              " 'acs',\n",
              " 'act',\n",
              " 'actally',\n",
              " 'actbr',\n",
              " 'acte',\n",
              " 'acted',\n",
              " 'actedalthough',\n",
              " 'actedand',\n",
              " 'actedblah',\n",
              " 'actedboth',\n",
              " 'actedbr',\n",
              " 'acteddirected',\n",
              " 'actedive',\n",
              " 'actedmanipulated',\n",
              " 'actedparticularly',\n",
              " 'actedsummer',\n",
              " 'actedthe',\n",
              " 'actedyou',\n",
              " 'actelone',\n",
              " 'actess',\n",
              " 'acteurs',\n",
              " 'acthe',\n",
              " 'acti',\n",
              " 'actif',\n",
              " 'actin',\n",
              " 'acting',\n",
              " 'actingabsolutely',\n",
              " 'actingalbert',\n",
              " 'actingalthough',\n",
              " 'actingan',\n",
              " 'actingand',\n",
              " 'actingapart',\n",
              " 'actingat',\n",
              " 'actingbad',\n",
              " 'actingboring',\n",
              " 'actingboss',\n",
              " 'actingbr',\n",
              " 'actingbrilliant',\n",
              " 'actingbut',\n",
              " 'actingcamera',\n",
              " 'actingcharacters',\n",
              " 'actingcheck',\n",
              " 'actingclass',\n",
              " 'actingcomedy',\n",
              " 'actingcrap',\n",
              " 'actingde',\n",
              " 'actingdialog',\n",
              " 'actingdirecting',\n",
              " 'actingdirectingcinematography',\n",
              " 'actingdirectingeffectsmusic',\n",
              " 'actingeffects',\n",
              " 'actingetc',\n",
              " 'actingetcbr',\n",
              " 'actingeven',\n",
              " 'actingexcept',\n",
              " 'actingfair',\n",
              " 'actingforthecamera',\n",
              " 'actinggood',\n",
              " 'actinggreat',\n",
              " 'actinghalf',\n",
              " 'actinghe',\n",
              " 'actinghow',\n",
              " 'actinghoweverwas',\n",
              " 'actingim',\n",
              " 'actingin',\n",
              " 'actingisms',\n",
              " 'actingits',\n",
              " 'actingjob',\n",
              " 'actingla',\n",
              " 'actinglack',\n",
              " 'actinglame',\n",
              " 'actingnicholas',\n",
              " 'actingno',\n",
              " 'actingoften',\n",
              " 'actingon',\n",
              " 'actingor',\n",
              " 'actingout',\n",
              " 'actingperformances',\n",
              " 'actingplot',\n",
              " 'actingplotdirectionwriting',\n",
              " 'actingread',\n",
              " 'actingreally',\n",
              " 'actingricci',\n",
              " 'actingrightdoesnt',\n",
              " 'actingrole',\n",
              " 'actingsactors',\n",
              " 'actingschool',\n",
              " 'actingso',\n",
              " 'actingsomewhat',\n",
              " 'actingsorry',\n",
              " 'actingspecial',\n",
              " 'actingstory',\n",
              " 'actingstreep',\n",
              " 'actingsubtle',\n",
              " 'actingterrible',\n",
              " 'actingthat',\n",
              " 'actingthats',\n",
              " 'actingthe',\n",
              " 'actingthere',\n",
              " 'actingthose',\n",
              " 'actingwell',\n",
              " 'actingwellhmmm',\n",
              " 'actingwhich',\n",
              " 'actingwise',\n",
              " 'actingwowit',\n",
              " 'actingwowthe',\n",
              " 'actingwriting',\n",
              " 'actingyou',\n",
              " 'actio',\n",
              " 'action',\n",
              " 'actiona',\n",
              " 'actionacting',\n",
              " 'actionadventure',\n",
              " 'actionadventureromancecomedies',\n",
              " 'actionand',\n",
              " 'actionanimation',\n",
              " 'actionbased',\n",
              " 'actionbiased',\n",
              " 'actionbloodgore',\n",
              " 'actionbr',\n",
              " 'actionbuff',\n",
              " 'actioncombat',\n",
              " 'actioncomedies',\n",
              " 'actioncomedy',\n",
              " 'actioncrime',\n",
              " 'actiondrama',\n",
              " 'actiondramaand',\n",
              " 'actiondramathriller',\n",
              " 'actioneer',\n",
              " 'actioneers',\n",
              " 'actioneffect',\n",
              " 'actionenhancement',\n",
              " 'actionepic',\n",
              " 'actioner',\n",
              " 'actionerbr',\n",
              " 'actioners',\n",
              " 'actionersbr',\n",
              " 'actionerthriller',\n",
              " 'actionespionagebr',\n",
              " 'actionexcitementeven',\n",
              " 'actionexploitation',\n",
              " 'actionextravaganza',\n",
              " 'actionfan',\n",
              " 'actionfantasy',\n",
              " 'actionfeature',\n",
              " 'actionfest',\n",
              " 'actionfight',\n",
              " 'actionfilled',\n",
              " 'actionfirstclass',\n",
              " 'actionflick',\n",
              " 'actionflickraised',\n",
              " 'actiongruesome',\n",
              " 'actionhajjbut',\n",
              " 'actionhalfanimated',\n",
              " 'actionherioc',\n",
              " 'actionhero',\n",
              " 'actionheroine',\n",
              " 'actionhorror',\n",
              " 'actionhorrorfilm',\n",
              " 'actionhorrorromanticcomedygenre',\n",
              " 'actionish',\n",
              " 'actionjunkie',\n",
              " 'actionlacking',\n",
              " 'actionless',\n",
              " 'actionlevel',\n",
              " 'actionlike',\n",
              " 'actionloaded',\n",
              " 'actionlovers',\n",
              " ...]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJbzUnaHjfli"
      },
      "source": [
        "- Even though there are still weird tokens, I cleaned and removed the weirdest ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNJp8GgfEeX_",
        "outputId": "20166b30-fab6-4bf1-eb4c-78b5adb4c048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There is 47568 Word2Vec vectors out of 143522 total IMDB vocabulary words.\n"
          ]
        }
      ],
      "source": [
        "## Building the embbedding matrix by firstly random initialzation for all words,\n",
        "## then setting the vector at index 0 to zeros for padding, and then overwriting\n",
        "## the real vectors from Word2Vec.\n",
        "\n",
        "imdb_vocab_size = len(imdb_vocab) + 1\n",
        "\n",
        "pretrained_embeddings = np.random.uniform(-0.25, 0.25, (imdb_vocab_size, 300))\n",
        "\n",
        "pretrained_embeddings[0] = np.zeros(300)\n",
        "\n",
        "real_vectors = 0\n",
        "for word, idx in word_to_idx.items():\n",
        "    if word in word2vec_model:\n",
        "        pretrained_embeddings[idx] = word2vec_model[word]\n",
        "        real_vectors += 1\n",
        "\n",
        "print(\"There is {} Word2Vec vectors out of {} total IMDB vocabulary words.\".format(real_vectors, imdb_vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QZHtch8SG49A"
      },
      "outputs": [],
      "source": [
        "## https://medium.com/@reddyyashu20/build-text-classification-model-using-word2vec-nlp-part2-52aa2839e8f4\n",
        "## https://www.kaggle.com/code/namyang94/imdb-sentiment-classification-methods\n",
        "\n",
        "## After the research, I gathered that I need to average vectors for traditional\n",
        "## ML model by converting each review into a 300-dim feature vector. So, Word2Vec\n",
        "## gave me 300-dim vector for each word -which is what the sample code does and\n",
        "## it works for LSTM-, but I need one one 300-dim vector per review for Logistic\n",
        "## Regression and I am doing that by taking average.\n",
        "\n",
        "imdb_train_vectors_avg = []\n",
        "for tokens in imdb_train_lemmatized:\n",
        "    vectors = []\n",
        "    for word in tokens:\n",
        "        if word in word2vec_model:\n",
        "            vectors.append(word2vec_model[word])\n",
        "    if len(vectors) > 0:\n",
        "        avg_vector = np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        avg_vector = np.zeros(300)\n",
        "    imdb_train_vectors_avg.append(avg_vector)\n",
        "\n",
        "imdb_test_vectors_avg = []\n",
        "for tokens in imdb_test_lemmatized:\n",
        "    vectors = []\n",
        "    for word in tokens:\n",
        "        if word in word2vec_model:\n",
        "            vectors.append(word2vec_model[word])\n",
        "    if len(vectors) > 0:\n",
        "        avg_vector = np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        avg_vector = np.zeros(300)\n",
        "    imdb_test_vectors_avg.append(avg_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o_PWmanGP_v4",
        "outputId": "0f4ce4ec-0def-42dd-c557-17b837bee2da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 5.45742922e-02,  1.61846559e-02,  1.04651786e-03,  8.44756216e-02,\n",
              "       -5.92256747e-02,  2.73378547e-02,  6.51020110e-02, -6.08244427e-02,\n",
              "        8.19856822e-02,  6.78403825e-02, -3.53200883e-02, -1.27185091e-01,\n",
              "       -2.57275421e-02,  4.43600751e-02, -1.12662576e-01,  1.00253247e-01,\n",
              "        4.38146479e-02,  1.13928519e-01, -7.33057642e-03, -8.67346525e-02,\n",
              "       -2.29286426e-03,  4.60926853e-02,  7.65669048e-02,  3.45746428e-03,\n",
              "        5.04747443e-02, -3.55456881e-02, -7.85460845e-02,  4.10671830e-02,\n",
              "        2.07941551e-02, -7.33971130e-03, -7.33301565e-02,  2.19822899e-02,\n",
              "       -4.04082388e-02, -4.14172094e-03,  7.59471513e-05, -2.26715412e-02,\n",
              "        5.49776964e-02,  4.89208512e-02,  3.54861058e-02,  7.84990415e-02,\n",
              "        1.04250669e-01, -4.94368859e-02,  9.99694988e-02, -1.54750133e-02,\n",
              "       -3.04152165e-02, -4.96684387e-02, -5.76231293e-02, -5.24910027e-03,\n",
              "        1.59848724e-02,  2.01292131e-02, -3.81132178e-02,  3.87399457e-02,\n",
              "       -2.83316728e-02, -1.08354744e-02,  1.99872404e-02, -1.09117292e-02,\n",
              "       -3.22633237e-02, -7.43015856e-02,  4.90072998e-04, -7.81779662e-02,\n",
              "        1.73238702e-02,  6.09534085e-02, -7.21947998e-02, -5.02010323e-02,\n",
              "       -1.46561731e-02, -1.86320599e-02, -5.92979677e-02,  6.52991906e-02,\n",
              "       -2.40255687e-02,  6.51996881e-02,  3.62157337e-02,  4.35406789e-02,\n",
              "        4.78482582e-02,  1.67206470e-02, -1.64674819e-01, -4.44217250e-02,\n",
              "        5.29316217e-02,  6.54624030e-02,  5.82960099e-02,  7.33149350e-02,\n",
              "        5.86249633e-03, -2.52361111e-02,  7.78799364e-03, -4.69720997e-02,\n",
              "       -4.94246036e-02, -3.94798536e-03, -8.41501430e-02,  9.97502208e-02,\n",
              "        1.81713682e-02,  2.14516614e-02,  2.49833390e-02,  5.33768616e-05,\n",
              "       -7.93373585e-02, -2.00954005e-02, -2.46290732e-02, -5.67750409e-02,\n",
              "        3.94307561e-02,  4.08259705e-02,  3.14076734e-03, -3.42973657e-02,\n",
              "       -5.00399545e-02, -3.34071158e-03,  5.36844172e-02,  6.51724637e-03,\n",
              "       -2.27998681e-02, -4.41704951e-02, -2.19591707e-02, -4.52282317e-02,\n",
              "        3.58351320e-02, -7.10680634e-02, -6.43182322e-02, -2.97189672e-02,\n",
              "       -9.37731602e-05, -1.65468175e-02,  1.03618719e-01, -2.50834171e-02,\n",
              "        3.91022637e-02, -3.35054100e-02,  7.92209357e-02,  3.09714880e-02,\n",
              "       -7.06119314e-02,  4.44134790e-03, -3.07713132e-02,  4.69116233e-02,\n",
              "       -8.89907219e-03, -4.27089743e-02, -8.93015116e-02, -3.24179907e-03,\n",
              "        5.62594645e-03,  1.50117967e-02, -5.31300642e-02, -7.05304369e-02,\n",
              "       -2.90846396e-02,  1.24245603e-02, -2.09449418e-02, -2.73033176e-02,\n",
              "        6.06384641e-03,  5.17094275e-03, -4.88227326e-03,  2.48194803e-02,\n",
              "        5.82879595e-02, -8.42636600e-02,  1.01328373e-03,  1.12335132e-02,\n",
              "        1.77972969e-02,  8.98341928e-03, -2.81492677e-02, -2.86225602e-03,\n",
              "       -4.58370931e-02, -2.60621756e-02,  6.73779994e-02,  2.12181173e-02,\n",
              "       -4.59919348e-02,  5.70069887e-02, -4.03297879e-02, -7.23690838e-02,\n",
              "       -4.84533608e-02, -8.39344934e-02, -7.32723996e-02, -3.90116386e-02,\n",
              "       -4.45884187e-03,  7.08710626e-02,  3.23008895e-02,  2.26216950e-02,\n",
              "       -2.64909538e-03, -1.01064578e-01,  5.41189164e-02, -7.87893906e-02,\n",
              "       -1.13543505e-02,  6.83524413e-03, -9.73990113e-02, -1.54949538e-02,\n",
              "       -9.26018227e-03, -6.89037219e-02, -2.81711929e-02, -1.43301990e-02,\n",
              "        9.47315395e-02, -1.06503092e-01, -1.80895254e-02,  7.31516350e-03,\n",
              "       -6.22454546e-02, -4.80646454e-02,  2.97472589e-02, -1.08907968e-02,\n",
              "       -2.71628704e-02,  2.50991667e-03, -5.02917729e-02,  2.10847948e-02,\n",
              "        4.06426899e-02,  4.57871556e-02,  4.21228893e-02,  5.42989420e-03,\n",
              "        2.88912654e-02,  8.61077383e-03,  3.23189633e-05,  3.56741250e-02,\n",
              "       -1.18883885e-02,  6.73987670e-03, -9.02935192e-02, -4.91689630e-02,\n",
              "        5.46295475e-03,  6.33404478e-02, -7.23974854e-02, -1.11547429e-02,\n",
              "        4.20037471e-02, -5.76928444e-02, -4.01925445e-02, -5.39515726e-03,\n",
              "       -1.86149515e-02, -1.01776030e-02, -3.01602297e-02,  7.38614574e-02,\n",
              "       -5.00045158e-03, -9.13930219e-03, -1.18084766e-01, -1.15200002e-02,\n",
              "        5.04567921e-02, -3.05117220e-02, -8.42718482e-02, -2.37434842e-02,\n",
              "       -4.57195714e-02,  2.05457956e-02,  2.22248491e-03,  2.14389060e-02,\n",
              "        5.91136515e-02, -8.92818347e-03,  4.66898531e-02, -7.62369158e-03,\n",
              "        7.34871067e-03, -5.37506258e-03,  2.68517118e-02, -3.53792161e-02,\n",
              "       -1.99961811e-02,  3.53456326e-02,  8.94696414e-02,  7.96055049e-03,\n",
              "       -1.50655108e-02, -7.72718936e-02,  8.87354463e-02,  1.33335497e-02,\n",
              "        4.58854511e-02,  1.00032873e-02,  3.36591154e-03, -7.25370869e-02,\n",
              "       -4.02963795e-02,  3.27656306e-02,  7.33258016e-03,  5.28799295e-02,\n",
              "       -2.01048423e-02, -3.33230197e-02, -6.51434716e-03,  6.43560216e-02,\n",
              "        4.79907393e-02,  9.51027125e-02,  7.01958761e-02, -5.03092594e-02,\n",
              "        1.22248428e-02,  5.73653402e-03, -5.74232526e-02, -6.21122308e-02,\n",
              "       -3.53271030e-02, -5.46438992e-03, -5.56421094e-02,  1.99148972e-02,\n",
              "        3.23101766e-02,  1.08364373e-01, -3.47264223e-02, -2.66877469e-02,\n",
              "       -8.53325054e-02, -2.67394632e-02,  2.79806126e-02,  6.87094033e-02,\n",
              "        8.06457847e-02,  4.63934988e-02,  5.31368852e-02, -4.83873934e-02,\n",
              "       -5.72157204e-02, -8.59255567e-02, -4.85953428e-02,  3.61520387e-02,\n",
              "        2.36666314e-02, -3.83654498e-02,  3.50824036e-02,  5.56837320e-02,\n",
              "        2.19630767e-02,  1.35673652e-03, -8.42725113e-02, -1.11268936e-02,\n",
              "        2.19411664e-02,  4.12173420e-02, -5.67141436e-02,  5.77502027e-02,\n",
              "       -7.49490112e-02,  6.54962799e-03, -4.70275097e-02, -2.96923220e-02,\n",
              "        1.97093654e-03, -6.66538179e-02,  2.26856582e-02,  1.20047363e-03],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_train_vectors_avg[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS8Gppwx-dzK"
      },
      "source": [
        "- Word embedding part with word2vec took a lot of time, but after all those research and analysis about the example code, I was able to do that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSxloErbKIs6"
      },
      "source": [
        "#### **Step 3 and Step 4: Modeling and Performance Evaluation** ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7qmRc20Nn98"
      },
      "source": [
        "- I chose to proceed with Logistic Regression for ML and LSTM for DL models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "bnuhcSnYKgWb",
        "outputId": "e98b5f61-2501-45aa-84ef-bb5b146684a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Logistic Regression\n",
        "\n",
        "X_train_log_reg = np.array(imdb_train_vectors_avg)\n",
        "X_test_log_reg = np.array(imdb_test_vectors_avg)\n",
        "\n",
        "y_train_log_reg = imdb_df_train['label'].values\n",
        "y_test_log_reg = imdb_df_test['label'].values\n",
        "\n",
        "log_reg_model = LogisticRegression()\n",
        "log_reg_model.fit(X_train_log_reg, y_train_log_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWJ-v1tFKgYf",
        "outputId": "a5f80563-7f02-404d-e895-a4b36f4767f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Performance of Logistic Regression ---\n",
            "\n",
            "Precision --> 0.8447082096933729\n",
            "Recall    --> 0.8473903552292121\n",
            "F1 Score  --> 0.8460471567267683\n"
          ]
        }
      ],
      "source": [
        "y_pred_log_reg = log_reg_model.predict(X_test_log_reg)\n",
        "\n",
        "print(\"\\n--- Performance of Logistic Regression ---\\n\")\n",
        "print(\"Precision -->\", precision_score(y_test_log_reg, y_pred_log_reg))\n",
        "print(\"Recall    -->\", recall_score(y_test_log_reg, y_pred_log_reg))\n",
        "print(\"F1 Score  -->\", f1_score(y_test_log_reg, y_pred_log_reg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxtVP_uVT9XT"
      },
      "source": [
        "- Not using torch_text becomes heavily expensive for me because now I need to manually convert the text into padded index sequences to replicate \"text_field.vocab.stoi = word_to_idx\" for LSTM network. I was receiving error for torch_text library while uploading the dataset, so I needed to upload and prepare the dataset manually by downloading from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "d8gZYyBhKfSt"
      },
      "outputs": [],
      "source": [
        "## https://www.tensorflow.org/text/guide/tokenizers\n",
        "\n",
        "## Converting tokens into index sequences to feed LSTM because it takes integer sequences.\n",
        "## If it does not find an index, then I use 0.\n",
        "\n",
        "imdb_train_idx_seq = []\n",
        "for tokens in imdb_train_lemmatized:\n",
        "    sequence = []\n",
        "    for word in tokens:\n",
        "        idx = word_to_idx.get(word, 0)\n",
        "        sequence.append(idx)\n",
        "    imdb_train_idx_seq.append(sequence)\n",
        "\n",
        "imdb_test_idx_seq = []\n",
        "for tokens in imdb_test_lemmatized:\n",
        "    sequence = []\n",
        "    for word in tokens:\n",
        "        idx = word_to_idx.get(word, 0)\n",
        "        sequence.append(idx)\n",
        "    imdb_test_idx_seq.append(sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tVfIBhG0KfVJ"
      },
      "outputs": [],
      "source": [
        "## https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
        "## https://stackoverflow.com/questions/42943291/what-does-keras-io-preprocessing-sequence-pad-sequences-do\n",
        "\n",
        "## Here, I am padding the sequnces because I need vectors with uniform length.\n",
        "## Then, preparing the label arrays to pass into LSTM.\n",
        "\n",
        "X_train_lstm_padded = pad_sequences(imdb_train_idx_seq, maxlen=300, padding='post')\n",
        "X_test_lstm_padded = pad_sequences(imdb_test_idx_seq, maxlen=300, padding='post')\n",
        "\n",
        "y_train_lstm = np.array(imdb_df_train['label'].values, dtype=np.float32)\n",
        "y_test_lstm = np.array(imdb_df_test['label'].values, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "T8eSuRPKoU5x"
      },
      "outputs": [],
      "source": [
        "## LSTM Architecture, again, I tried to stick with the sample code but my\n",
        "## pipeline is different, so not everything stays same.\n",
        "\n",
        "class LSTMSentiment(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim=256):\n",
        "        super(LSTMSentiment, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.hidden2label = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_dim),\n",
        "                torch.zeros(1, batch_size, self.hidden_dim))\n",
        "\n",
        "    def forward(self, sentence, hidden):\n",
        "        embeddings = self.embedding(sentence)\n",
        "        lstm_out, hidden = self.lstm(embeddings, hidden)\n",
        "        last_output = lstm_out[-1]\n",
        "        out = self.hidden2label(last_output)\n",
        "        return torch.sigmoid(out).squeeze(1), hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uWodf3fVoU7-"
      },
      "outputs": [],
      "source": [
        "## https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "## https://discuss.pytorch.org/t/what-do-tensordataset-and-dataloader-do/107017\n",
        "## https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "## Here, creating dataloaders for training and testing because I need to handle manually\n",
        "## To do that, TensorDataset combines inputs and labels; DataLoader handles batching\n",
        "\n",
        "X_train_lstm_tensor = torch.tensor(X_train_lstm_padded, dtype=torch.long)\n",
        "X_test_lstm_tensor = torch.tensor(X_test_lstm_padded, dtype=torch.long)\n",
        "\n",
        "y_train_lstm_tensor = torch.tensor(y_train_lstm, dtype=torch.float32)\n",
        "y_test_lstm_tensor = torch.tensor(y_test_lstm, dtype=torch.float32)\n",
        "\n",
        "lstm_train_data = TensorDataset(X_train_lstm_tensor, y_train_lstm_tensor)\n",
        "lstm_test_data = TensorDataset(X_test_lstm_tensor, y_test_lstm_tensor)\n",
        "\n",
        "lstm_train_loader = DataLoader(lstm_train_data, batch_size=64, shuffle=True)\n",
        "lstm_test_loader = DataLoader(lstm_test_data, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etELcqyRaqDa",
        "outputId": "14cf4897-0871-4b14-a78b-d097ce42a25f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available --> True\n",
            "Current Device --> 0\n",
            "Device Name    --> Tesla T4\n"
          ]
        }
      ],
      "source": [
        "print(\"CUDA Available -->\", torch.cuda.is_available())\n",
        "print(\"Current Device -->\", torch.cuda.current_device())\n",
        "print(\"Device Name    -->\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAO6zvWcyw9U",
        "outputId": "43ee8ab0-7e99-49df-a95f-a9dd1ef5082d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "## https://www.geeksforgeeks.org/long-short-term-memory-networks-using-pytorch/\n",
        "## https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
        "\n",
        "## Training LSTM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = LSTMSentiment(pretrained_embeddings).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX9lq5tkyw_i",
        "outputId": "a48caba1-4a59-451f-b323-1b3f57e920cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 - Loss --> 432.3031\n",
            "Epoch 2/50 - Loss --> 404.6075\n",
            "Epoch 3/50 - Loss --> 389.2106\n",
            "Epoch 4/50 - Loss --> 389.2827\n",
            "Epoch 5/50 - Loss --> 417.5304\n",
            "Epoch 6/50 - Loss --> 386.1023\n",
            "Epoch 7/50 - Loss --> 376.3022\n",
            "Epoch 8/50 - Loss --> 369.9109\n",
            "Epoch 9/50 - Loss --> 222.6037\n",
            "Epoch 10/50 - Loss --> 196.9735\n",
            "Epoch 11/50 - Loss --> 184.1229\n",
            "Epoch 12/50 - Loss --> 202.8967\n",
            "Epoch 13/50 - Loss --> 194.9883\n",
            "Epoch 14/50 - Loss --> 146.4446\n",
            "Epoch 15/50 - Loss --> 132.4649\n",
            "Epoch 16/50 - Loss --> 114.1491\n",
            "Epoch 17/50 - Loss --> 94.8872\n",
            "Epoch 18/50 - Loss --> 77.8143\n",
            "Epoch 19/50 - Loss --> 66.5989\n",
            "Epoch 20/50 - Loss --> 51.3851\n",
            "Epoch 21/50 - Loss --> 43.0886\n",
            "Epoch 22/50 - Loss --> 37.4867\n",
            "Epoch 23/50 - Loss --> 32.4083\n",
            "Epoch 24/50 - Loss --> 31.3223\n",
            "Epoch 25/50 - Loss --> 25.2791\n",
            "Epoch 26/50 - Loss --> 26.9831\n",
            "Epoch 27/50 - Loss --> 22.0892\n",
            "Epoch 28/50 - Loss --> 21.5223\n",
            "Epoch 29/50 - Loss --> 19.6698\n",
            "Epoch 30/50 - Loss --> 18.0054\n",
            "Epoch 31/50 - Loss --> 18.0514\n",
            "Epoch 32/50 - Loss --> 16.9821\n",
            "Epoch 33/50 - Loss --> 19.0366\n",
            "Epoch 34/50 - Loss --> 16.1097\n",
            "Epoch 35/50 - Loss --> 14.4118\n",
            "Epoch 36/50 - Loss --> 16.2685\n",
            "Epoch 37/50 - Loss --> 14.1066\n",
            "Epoch 38/50 - Loss --> 16.0714\n",
            "Epoch 39/50 - Loss --> 14.8891\n",
            "Epoch 40/50 - Loss --> 13.4921\n",
            "Epoch 41/50 - Loss --> 13.7907\n",
            "Epoch 42/50 - Loss --> 24.5299\n",
            "Epoch 43/50 - Loss --> 12.1317\n",
            "Epoch 44/50 - Loss --> 10.8374\n",
            "Epoch 45/50 - Loss --> 14.3876\n",
            "Epoch 46/50 - Loss --> 11.2422\n",
            "Epoch 47/50 - Loss --> 13.3652\n",
            "Epoch 48/50 - Loss --> 12.5377\n",
            "Epoch 49/50 - Loss --> 12.3817\n",
            "Epoch 50/50 - Loss --> 11.7654\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in lstm_train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        inputs = inputs.permute(1, 0)\n",
        "\n",
        "        hidden = model.init_hidden(inputs.shape[1])\n",
        "        h_0, c_0 = hidden[0].to(device), hidden[1].to(device)\n",
        "        hidden = (h_0, c_0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, hidden = model(inputs, hidden)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(\"Epoch {}/{} - Loss --> {:.4f}\".format(epoch+1, epochs, total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn5OXhJDyxBy",
        "outputId": "8a0d8126-4784-4198-9cc5-4b02f3dd9bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Performance of LSTM Model ---\n",
            "\n",
            "Precision --> 0.8648275862068966\n",
            "Recall    --> 0.8710061520142885\n",
            "F1 Score  --> 0.8679058730472612\n"
          ]
        }
      ],
      "source": [
        "## Performance evaluation for LSTM\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in lstm_test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        inputs = inputs.permute(1, 0)\n",
        "        hidden = model.init_hidden(inputs.shape[1])\n",
        "        h_0, c_0 = hidden[0].to(device), hidden[1].to(device)\n",
        "        hidden = (h_0, c_0)\n",
        "\n",
        "        outputs, hidden = model(inputs, hidden)\n",
        "        preds = (outputs > 0.5).int().cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "precision = precision_score(all_labels, all_preds)\n",
        "recall = recall_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "print(\"\\n--- Performance of LSTM Model ---\\n\")\n",
        "print(\"Precision -->\", precision)\n",
        "print(\"Recall    -->\", recall)\n",
        "print(\"F1 Score  -->\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odcr-bnVVSm8"
      },
      "source": [
        "- That's the end of the implementation and results. My findings with the analysis including all necessary parts can be found in my report; I tried not to write too much here."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
